{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPV8YHcNKFSQ9nZWkGJIg6C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luixlu-wq/pb-learn-nn-p1/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tGgijtVVoPwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "aOURYeNljxgd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()\n",
        "\n",
        "train_data = datasets.MNIST(root='/cnn_data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='/cnn_data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "y5OwkhmZkcpO",
        "outputId": "ac1f27b7-24ee-495d-da90-957ef8bb2236"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 57.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.72MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.7MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=10, shuffle=False)\n",
        "\n",
        "conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
        "conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, stride=1, padding=1)"
      ],
      "metadata": {
        "id": "_3TeKN1bn6el"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (X_train, y_train) in enumerate(train_data):\n",
        "    print(i, X_train, y_train)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TzpTGaF6phT4",
        "outputId": "3550eb60-9819-4536-d79f-787a6e140536"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
            "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
            "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
            "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
            "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
            "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
            "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
            "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
            "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
            "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
            "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
            "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
            "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
            "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
            "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
            "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
            "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
            "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
            "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]]]) 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = F.relu(conv1(X_train.view(-1, 1, 28, 28)))\n",
        "print(x.shape)\n",
        "x = F.max_pool2d(x, 2, 2)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3S6M7T2q2aN",
        "outputId": "d1665845-0f22-4b26-f707-f2bc3103b3eb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6, 28, 28])\n",
            "torch.Size([1, 6, 14, 14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = F.relu(conv2(x))\n",
        "print(x.shape)\n",
        "x = F.max_pool2d(x, 2, 2)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znhgzaqRsV-y",
        "outputId": "3311a1ab-4e5e-4559-f926-281bb01cfdcd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 16, 14, 14])\n",
            "torch.Size([1, 16, 7, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(in_features=7*7*16, out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "        self.fc3 = nn.Linear(in_features=60, out_features=10)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = F.relu(self.conv1(X))\n",
        "        X = F.max_pool2d(X, 2, 2)\n",
        "        X = F.relu(self.conv2(X))\n",
        "        X = F.max_pool2d(X, 2, 2)\n",
        "        X = X.view(-1, 7*7*16)\n",
        "\n",
        "        X = F.relu(self.fc1(X))\n",
        "        X = F.relu(self.fc2(X))\n",
        "        X = self.fc3(X)\n",
        "\n",
        "        return F.log_softmax(X, dim=1)\n"
      ],
      "metadata": {
        "id": "Bkf25l5ls7vM"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(101)\n",
        "model = CNNModel()\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCM5y9D8uQSv",
        "outputId": "1f967cc9-eb83-40b4-e08f-586f51cba6e8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
              "  (fc3): Linear(in_features=60, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "start_time = time.time()\n",
        "epochs = 10\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_correct = []\n",
        "test_correct = []\n",
        "\n",
        "for i in range(epochs):\n",
        "    trn_corr = 0\n",
        "    tst_corr = 0\n",
        "\n",
        "    for b, (X_train, y_train) in enumerate(train_loader):\n",
        "        b += 1\n",
        "\n",
        "        y_pred = model(X_train)\n",
        "        loss = criterion(y_pred, y_train)\n",
        "\n",
        "        predicted = torch.max(y_pred.data, 1)[1]\n",
        "        batch_corr = (predicted == y_train).sum()\n",
        "        trn_corr += batch_corr\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if b % 500 == 0:\n",
        "            print(f'epoch: {i}  batch: {b}  loss: {loss.item()}  \\accuracy: {trn_corr.item()*100/(10*b)}%')\n",
        "    train_losses.append(loss)\n",
        "    train_correct.append(trn_corr)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for b, (X_test, y_test) in enumerate(test_loader):\n",
        "            y_val = model(X_test)\n",
        "            predicted = torch.max(y_val.data, 1)[1]\n",
        "            tst_corr += (predicted == y_test).sum()\n",
        "\n",
        "    loss = criterion(y_val, y_test)\n",
        "    test_losses.append(loss)\n",
        "    test_correct.append(tst_corr)\n",
        "\n",
        "current_time = time.time()\n",
        "total_time = current_time - start_time\n",
        "print(f'total time: {total_time}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZgbAjBDruQGw",
        "outputId": "b8ed74a5-d204-4fd4-9d4c-8f42dc9ca4d8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0  batch: 50  loss: 0.018693899735808372  \u0007ccuracy: 99.2%\n",
            "epoch: 0  batch: 100  loss: 1.5497205652081902e-07  \u0007ccuracy: 99.0%\n",
            "epoch: 0  batch: 150  loss: 0.416245698928833  \u0007ccuracy: 99.06666666666666%\n",
            "epoch: 0  batch: 200  loss: 8.976318895292934e-06  \u0007ccuracy: 99.15%\n",
            "epoch: 0  batch: 250  loss: 0.009877174161374569  \u0007ccuracy: 99.2%\n",
            "epoch: 0  batch: 300  loss: 0.010617902502417564  \u0007ccuracy: 99.16666666666667%\n",
            "epoch: 0  batch: 350  loss: 7.998782166396268e-06  \u0007ccuracy: 99.2%\n",
            "epoch: 0  batch: 400  loss: 0.0008931534248404205  \u0007ccuracy: 99.2%\n",
            "epoch: 0  batch: 450  loss: 0.0022063013166189194  \u0007ccuracy: 99.2%\n",
            "epoch: 0  batch: 500  loss: 6.613595178350806e-05  \u0007ccuracy: 99.2%\n",
            "epoch: 0  batch: 550  loss: 0.002711246022954583  \u0007ccuracy: 99.21818181818182%\n",
            "epoch: 0  batch: 600  loss: 4.947147317579947e-06  \u0007ccuracy: 99.16666666666667%\n",
            "epoch: 0  batch: 650  loss: 0.09533095359802246  \u0007ccuracy: 99.16923076923077%\n",
            "epoch: 0  batch: 700  loss: 0.06421749293804169  \u0007ccuracy: 99.22857142857143%\n",
            "epoch: 0  batch: 750  loss: 0.0009479612926952541  \u0007ccuracy: 99.25333333333333%\n",
            "epoch: 0  batch: 800  loss: 0.00367492507211864  \u0007ccuracy: 99.25%\n",
            "epoch: 0  batch: 850  loss: 4.51727828476578e-05  \u0007ccuracy: 99.2235294117647%\n",
            "epoch: 0  batch: 900  loss: 0.0009227611008100212  \u0007ccuracy: 99.17777777777778%\n",
            "epoch: 0  batch: 950  loss: 0.01340609509497881  \u0007ccuracy: 99.16842105263157%\n",
            "epoch: 0  batch: 1000  loss: 0.00035005167592316866  \u0007ccuracy: 99.18%\n",
            "epoch: 0  batch: 1050  loss: 0.0045470246113836765  \u0007ccuracy: 99.19047619047619%\n",
            "epoch: 0  batch: 1100  loss: 0.0032917787320911884  \u0007ccuracy: 99.2090909090909%\n",
            "epoch: 0  batch: 1150  loss: 0.0005477884551510215  \u0007ccuracy: 99.20869565217392%\n",
            "epoch: 0  batch: 1200  loss: 1.8619386537466198e-05  \u0007ccuracy: 99.225%\n",
            "epoch: 0  batch: 1250  loss: 8.439897646894678e-05  \u0007ccuracy: 99.232%\n",
            "epoch: 0  batch: 1300  loss: 0.00019166382844559848  \u0007ccuracy: 99.22307692307692%\n",
            "epoch: 0  batch: 1350  loss: 0.011923926882445812  \u0007ccuracy: 99.22222222222223%\n",
            "epoch: 0  batch: 1400  loss: 6.0376827605068684e-05  \u0007ccuracy: 99.21428571428571%\n",
            "epoch: 0  batch: 1450  loss: 0.07462958991527557  \u0007ccuracy: 99.22068965517241%\n",
            "epoch: 0  batch: 1500  loss: 0.08457229286432266  \u0007ccuracy: 99.21333333333334%\n",
            "epoch: 0  batch: 1550  loss: 0.00962055940181017  \u0007ccuracy: 99.21290322580646%\n",
            "epoch: 0  batch: 1600  loss: 0.00022472385899163783  \u0007ccuracy: 99.2%\n",
            "epoch: 0  batch: 1650  loss: 0.007027821149677038  \u0007ccuracy: 99.18787878787879%\n",
            "epoch: 0  batch: 1700  loss: 0.0002802246599458158  \u0007ccuracy: 99.18823529411765%\n",
            "epoch: 0  batch: 1750  loss: 1.679602064541541e-05  \u0007ccuracy: 99.18857142857142%\n",
            "epoch: 0  batch: 1800  loss: 0.02615799568593502  \u0007ccuracy: 99.18333333333334%\n",
            "epoch: 0  batch: 1850  loss: 4.21253644162789e-05  \u0007ccuracy: 99.18378378378378%\n",
            "epoch: 0  batch: 1900  loss: 0.0002893772616516799  \u0007ccuracy: 99.1842105263158%\n",
            "epoch: 0  batch: 1950  loss: 0.012917396612465382  \u0007ccuracy: 99.18461538461538%\n",
            "epoch: 0  batch: 2000  loss: 0.00029854761669412255  \u0007ccuracy: 99.2%\n",
            "epoch: 0  batch: 2050  loss: 3.629433922469616e-05  \u0007ccuracy: 99.21951219512195%\n",
            "epoch: 0  batch: 2100  loss: 6.3537418100168e-06  \u0007ccuracy: 99.22857142857143%\n",
            "epoch: 0  batch: 2150  loss: 0.06715808808803558  \u0007ccuracy: 99.21860465116279%\n",
            "epoch: 0  batch: 2200  loss: 0.001957677071914077  \u0007ccuracy: 99.2090909090909%\n",
            "epoch: 0  batch: 2250  loss: 0.009561165235936642  \u0007ccuracy: 99.21333333333334%\n",
            "epoch: 0  batch: 2300  loss: 4.832958438782953e-05  \u0007ccuracy: 99.21739130434783%\n",
            "epoch: 0  batch: 2350  loss: 0.00684245815500617  \u0007ccuracy: 99.22127659574468%\n",
            "epoch: 0  batch: 2400  loss: 0.00014726605149917305  \u0007ccuracy: 99.22916666666667%\n",
            "epoch: 0  batch: 2450  loss: 0.0010671243071556091  \u0007ccuracy: 99.22857142857143%\n",
            "epoch: 0  batch: 2500  loss: 0.01913858763873577  \u0007ccuracy: 99.24%\n",
            "epoch: 0  batch: 2550  loss: 0.003035166533663869  \u0007ccuracy: 99.2392156862745%\n",
            "epoch: 0  batch: 2600  loss: 0.00021033648226875812  \u0007ccuracy: 99.23461538461538%\n",
            "epoch: 0  batch: 2650  loss: 0.0003315569192636758  \u0007ccuracy: 99.20754716981132%\n",
            "epoch: 0  batch: 2700  loss: 0.0003453911922406405  \u0007ccuracy: 99.21111111111111%\n",
            "epoch: 0  batch: 2750  loss: 0.0024932976812124252  \u0007ccuracy: 99.2%\n",
            "epoch: 0  batch: 2800  loss: 0.00018098442524205893  \u0007ccuracy: 99.18214285714286%\n",
            "epoch: 0  batch: 2850  loss: 0.0003886273188982159  \u0007ccuracy: 99.1859649122807%\n",
            "epoch: 0  batch: 2900  loss: 0.0006030722870491445  \u0007ccuracy: 99.18620689655172%\n",
            "epoch: 0  batch: 2950  loss: 8.367846749024466e-05  \u0007ccuracy: 99.18305084745762%\n",
            "epoch: 0  batch: 3000  loss: 0.0024003381840884686  \u0007ccuracy: 99.18666666666667%\n",
            "epoch: 0  batch: 3050  loss: 0.0012169473338872194  \u0007ccuracy: 99.18688524590164%\n",
            "epoch: 0  batch: 3100  loss: 0.0015965430065989494  \u0007ccuracy: 99.18709677419355%\n",
            "epoch: 0  batch: 3150  loss: 0.005824928637593985  \u0007ccuracy: 99.18412698412699%\n",
            "epoch: 0  batch: 3200  loss: 0.002667616354301572  \u0007ccuracy: 99.18125%\n",
            "epoch: 0  batch: 3250  loss: 0.011003976687788963  \u0007ccuracy: 99.18461538461538%\n",
            "epoch: 0  batch: 3300  loss: 8.252599218394607e-05  \u0007ccuracy: 99.19393939393939%\n",
            "epoch: 0  batch: 3350  loss: 0.03148811683058739  \u0007ccuracy: 99.19701492537314%\n",
            "epoch: 0  batch: 3400  loss: 7.808093869243748e-06  \u0007ccuracy: 99.19705882352942%\n",
            "epoch: 0  batch: 3450  loss: 0.00564310560002923  \u0007ccuracy: 99.19710144927537%\n",
            "epoch: 0  batch: 3500  loss: 0.0001810363173717633  \u0007ccuracy: 99.2%\n",
            "epoch: 0  batch: 3550  loss: 0.009686587378382683  \u0007ccuracy: 99.19718309859155%\n",
            "epoch: 0  batch: 3600  loss: 0.0004730219952762127  \u0007ccuracy: 99.19166666666666%\n",
            "epoch: 0  batch: 3650  loss: 0.007027295418083668  \u0007ccuracy: 99.1945205479452%\n",
            "epoch: 0  batch: 3700  loss: 0.00010690429189708084  \u0007ccuracy: 99.19459459459459%\n",
            "epoch: 0  batch: 3750  loss: 0.0007732894155196846  \u0007ccuracy: 99.2%\n",
            "epoch: 0  batch: 3800  loss: 3.833363371086307e-05  \u0007ccuracy: 99.2%\n",
            "epoch: 0  batch: 3850  loss: 0.0054776426404714584  \u0007ccuracy: 99.20519480519481%\n",
            "epoch: 0  batch: 3900  loss: 0.003825028194114566  \u0007ccuracy: 99.20769230769231%\n",
            "epoch: 0  batch: 3950  loss: 1.6331616734532872e-06  \u0007ccuracy: 99.2126582278481%\n",
            "epoch: 0  batch: 4000  loss: 0.00023483179393224418  \u0007ccuracy: 99.2075%\n",
            "epoch: 0  batch: 4050  loss: 0.00011647570499917492  \u0007ccuracy: 99.2%\n",
            "epoch: 0  batch: 4100  loss: 0.0050212787464261055  \u0007ccuracy: 99.2%\n",
            "epoch: 0  batch: 4150  loss: 9.213401790475473e-05  \u0007ccuracy: 99.19036144578314%\n",
            "epoch: 0  batch: 4200  loss: 0.0002670438261702657  \u0007ccuracy: 99.17619047619047%\n",
            "epoch: 0  batch: 4250  loss: 0.0017591433133929968  \u0007ccuracy: 99.17882352941176%\n",
            "epoch: 0  batch: 4300  loss: 0.0002519330882932991  \u0007ccuracy: 99.16744186046512%\n",
            "epoch: 0  batch: 4350  loss: 0.1255282461643219  \u0007ccuracy: 99.1632183908046%\n",
            "epoch: 0  batch: 4400  loss: 0.004889254458248615  \u0007ccuracy: 99.16136363636363%\n",
            "epoch: 0  batch: 4450  loss: 5.8078632719116285e-05  \u0007ccuracy: 99.161797752809%\n",
            "epoch: 0  batch: 4500  loss: 0.0003297326329629868  \u0007ccuracy: 99.15777777777778%\n",
            "epoch: 0  batch: 4550  loss: 0.0005761223146691918  \u0007ccuracy: 99.15824175824176%\n",
            "epoch: 0  batch: 4600  loss: 0.007231342140585184  \u0007ccuracy: 99.16304347826087%\n",
            "epoch: 0  batch: 4650  loss: 0.00028173887403681874  \u0007ccuracy: 99.16989247311828%\n",
            "epoch: 0  batch: 4700  loss: 9.405502169101965e-06  \u0007ccuracy: 99.17021276595744%\n",
            "epoch: 0  batch: 4750  loss: 0.06316039711236954  \u0007ccuracy: 99.17263157894737%\n",
            "epoch: 0  batch: 4800  loss: 0.000637633609585464  \u0007ccuracy: 99.16875%\n",
            "epoch: 0  batch: 4850  loss: 0.0002537340042181313  \u0007ccuracy: 99.16701030927835%\n",
            "epoch: 0  batch: 4900  loss: 1.0692876458051614e-05  \u0007ccuracy: 99.16734693877551%\n",
            "epoch: 0  batch: 4950  loss: 8.676064317114651e-05  \u0007ccuracy: 99.16363636363636%\n",
            "epoch: 0  batch: 5000  loss: 0.029193630442023277  \u0007ccuracy: 99.166%\n",
            "epoch: 0  batch: 5050  loss: 0.0016424307832494378  \u0007ccuracy: 99.15841584158416%\n",
            "epoch: 0  batch: 5100  loss: 1.91084727703128e-05  \u0007ccuracy: 99.16274509803921%\n",
            "epoch: 0  batch: 5150  loss: 6.882433808641508e-05  \u0007ccuracy: 99.16504854368932%\n",
            "epoch: 0  batch: 5200  loss: 0.001571320928633213  \u0007ccuracy: 99.17115384615384%\n",
            "epoch: 0  batch: 5250  loss: 0.004225225653499365  \u0007ccuracy: 99.16952380952381%\n",
            "epoch: 0  batch: 5300  loss: 0.06701407581567764  \u0007ccuracy: 99.16981132075472%\n",
            "epoch: 0  batch: 5350  loss: 0.016962150111794472  \u0007ccuracy: 99.17009345794392%\n",
            "epoch: 0  batch: 5400  loss: 0.0004098009376320988  \u0007ccuracy: 99.17222222222222%\n",
            "epoch: 0  batch: 5450  loss: 0.03463754057884216  \u0007ccuracy: 99.16880733944954%\n",
            "epoch: 0  batch: 5500  loss: 0.019630325958132744  \u0007ccuracy: 99.17454545454545%\n",
            "epoch: 0  batch: 5550  loss: 0.003789963200688362  \u0007ccuracy: 99.17477477477478%\n",
            "epoch: 0  batch: 5600  loss: 5.393307583290152e-05  \u0007ccuracy: 99.17142857142858%\n",
            "epoch: 0  batch: 5650  loss: 0.0002640454622451216  \u0007ccuracy: 99.17345132743363%\n",
            "epoch: 0  batch: 5700  loss: 0.0020061922259628773  \u0007ccuracy: 99.17368421052632%\n",
            "epoch: 0  batch: 5750  loss: 0.033389266580343246  \u0007ccuracy: 99.17217391304348%\n",
            "epoch: 0  batch: 5800  loss: 0.009104890748858452  \u0007ccuracy: 99.17413793103448%\n",
            "epoch: 0  batch: 5850  loss: 0.0013719017151743174  \u0007ccuracy: 99.17094017094017%\n",
            "epoch: 0  batch: 5900  loss: 0.02541438117623329  \u0007ccuracy: 99.16949152542372%\n",
            "epoch: 0  batch: 5950  loss: 0.0010846328223124146  \u0007ccuracy: 99.17142857142858%\n",
            "epoch: 0  batch: 6000  loss: 3.29230897477828e-05  \u0007ccuracy: 99.175%\n",
            "epoch: 1  batch: 50  loss: 0.0011785788228735328  \u0007ccuracy: 98.6%\n",
            "epoch: 1  batch: 100  loss: 0.000682651239912957  \u0007ccuracy: 99.0%\n",
            "epoch: 1  batch: 150  loss: 0.00016048767429310828  \u0007ccuracy: 99.06666666666666%\n",
            "epoch: 1  batch: 200  loss: 0.0006194516899995506  \u0007ccuracy: 99.25%\n",
            "epoch: 1  batch: 250  loss: 0.00040734102367423475  \u0007ccuracy: 99.28%\n",
            "epoch: 1  batch: 300  loss: 6.857106200186536e-05  \u0007ccuracy: 99.33333333333333%\n",
            "epoch: 1  batch: 350  loss: 0.0013428365346044302  \u0007ccuracy: 99.14285714285714%\n",
            "epoch: 1  batch: 400  loss: 0.0008571484941057861  \u0007ccuracy: 99.2%\n",
            "epoch: 1  batch: 450  loss: 0.08955230563879013  \u0007ccuracy: 99.17777777777778%\n",
            "epoch: 1  batch: 500  loss: 0.00042352027958258986  \u0007ccuracy: 99.18%\n",
            "epoch: 1  batch: 550  loss: 0.00023570971097797155  \u0007ccuracy: 99.2%\n",
            "epoch: 1  batch: 600  loss: 4.5069162297295406e-05  \u0007ccuracy: 99.2%\n",
            "epoch: 1  batch: 650  loss: 0.0035872296430170536  \u0007ccuracy: 99.24615384615385%\n",
            "epoch: 1  batch: 700  loss: 0.0011129353661090136  \u0007ccuracy: 99.22857142857143%\n",
            "epoch: 1  batch: 750  loss: 0.002334983553737402  \u0007ccuracy: 99.24%\n",
            "epoch: 1  batch: 800  loss: 0.00010644398571457714  \u0007ccuracy: 99.275%\n",
            "epoch: 1  batch: 850  loss: 0.003660542191937566  \u0007ccuracy: 99.24705882352941%\n",
            "epoch: 1  batch: 900  loss: 0.00015006955072749406  \u0007ccuracy: 99.24444444444444%\n",
            "epoch: 1  batch: 950  loss: 0.029330557212233543  \u0007ccuracy: 99.26315789473684%\n",
            "epoch: 1  batch: 1000  loss: 2.208888872701209e-05  \u0007ccuracy: 99.26%\n",
            "epoch: 1  batch: 1050  loss: 6.627995844610268e-06  \u0007ccuracy: 99.26666666666667%\n",
            "epoch: 1  batch: 1100  loss: 0.0002853336918633431  \u0007ccuracy: 99.27272727272727%\n",
            "epoch: 1  batch: 1150  loss: 0.00015256564074661583  \u0007ccuracy: 99.27826086956522%\n",
            "epoch: 1  batch: 1200  loss: 0.0004422226920723915  \u0007ccuracy: 99.275%\n",
            "epoch: 1  batch: 1250  loss: 0.00023644840985070914  \u0007ccuracy: 99.296%\n",
            "epoch: 1  batch: 1300  loss: 0.081017404794693  \u0007ccuracy: 99.26153846153846%\n",
            "epoch: 1  batch: 1350  loss: 3.981287591159344e-05  \u0007ccuracy: 99.25185185185185%\n",
            "epoch: 1  batch: 1400  loss: 0.013487674295902252  \u0007ccuracy: 99.22142857142858%\n",
            "epoch: 1  batch: 1450  loss: 4.7261994041036814e-05  \u0007ccuracy: 99.24137931034483%\n",
            "epoch: 1  batch: 1500  loss: 0.010597002692520618  \u0007ccuracy: 99.24%\n",
            "epoch: 1  batch: 1550  loss: 0.0002872115874197334  \u0007ccuracy: 99.2516129032258%\n",
            "epoch: 1  batch: 1600  loss: 0.003231511916965246  \u0007ccuracy: 99.25625%\n",
            "epoch: 1  batch: 1650  loss: 0.006638475693762302  \u0007ccuracy: 99.25454545454545%\n",
            "epoch: 1  batch: 1700  loss: 0.002504488918930292  \u0007ccuracy: 99.2764705882353%\n",
            "epoch: 1  batch: 1750  loss: 0.0016624676063656807  \u0007ccuracy: 99.28571428571429%\n",
            "epoch: 1  batch: 1800  loss: 0.0001039462149492465  \u0007ccuracy: 99.3%\n",
            "epoch: 1  batch: 1850  loss: 0.00027353843324817717  \u0007ccuracy: 99.30810810810812%\n",
            "epoch: 1  batch: 1900  loss: 2.3841843699301535e-07  \u0007ccuracy: 99.3157894736842%\n",
            "epoch: 1  batch: 1950  loss: 6.921675230842084e-05  \u0007ccuracy: 99.2974358974359%\n",
            "epoch: 1  batch: 2000  loss: 0.00017964695871341974  \u0007ccuracy: 99.295%\n",
            "epoch: 1  batch: 2050  loss: 0.006932053714990616  \u0007ccuracy: 99.29268292682927%\n",
            "epoch: 1  batch: 2100  loss: 0.2503512501716614  \u0007ccuracy: 99.29523809523809%\n",
            "epoch: 1  batch: 2150  loss: 3.336276131449267e-05  \u0007ccuracy: 99.30232558139535%\n",
            "epoch: 1  batch: 2200  loss: 0.9319425821304321  \u0007ccuracy: 99.29545454545455%\n",
            "epoch: 1  batch: 2250  loss: 3.6758639907930046e-05  \u0007ccuracy: 99.29777777777778%\n",
            "epoch: 1  batch: 2300  loss: 0.03275081515312195  \u0007ccuracy: 99.3%\n",
            "epoch: 1  batch: 2350  loss: 0.00019153484026901424  \u0007ccuracy: 99.29787234042553%\n",
            "epoch: 1  batch: 2400  loss: 0.007045670412480831  \u0007ccuracy: 99.3%\n",
            "epoch: 1  batch: 2450  loss: 4.547238495433703e-05  \u0007ccuracy: 99.3061224489796%\n",
            "epoch: 1  batch: 2500  loss: 0.7392659187316895  \u0007ccuracy: 99.3%\n",
            "epoch: 1  batch: 2550  loss: 0.000765003904234618  \u0007ccuracy: 99.29803921568627%\n",
            "epoch: 1  batch: 2600  loss: 0.017825696617364883  \u0007ccuracy: 99.3%\n",
            "epoch: 1  batch: 2650  loss: 0.0008598348358646035  \u0007ccuracy: 99.29433962264152%\n",
            "epoch: 1  batch: 2700  loss: 6.0745089285774156e-05  \u0007ccuracy: 99.28148148148148%\n",
            "epoch: 1  batch: 2750  loss: 0.0009045106125995517  \u0007ccuracy: 99.28727272727272%\n",
            "epoch: 1  batch: 2800  loss: 0.05882086232304573  \u0007ccuracy: 99.28214285714286%\n",
            "epoch: 1  batch: 2850  loss: 0.0011258285958319902  \u0007ccuracy: 99.28771929824562%\n",
            "epoch: 1  batch: 2900  loss: 0.026263579726219177  \u0007ccuracy: 99.27931034482759%\n",
            "epoch: 1  batch: 2950  loss: 0.0011723823845386505  \u0007ccuracy: 99.26440677966102%\n",
            "epoch: 1  batch: 3000  loss: 0.00026699737645685673  \u0007ccuracy: 99.26%\n",
            "epoch: 1  batch: 3050  loss: 1.3232209994384903e-06  \u0007ccuracy: 99.26885245901639%\n",
            "epoch: 1  batch: 3100  loss: 0.0005314142326824367  \u0007ccuracy: 99.2741935483871%\n",
            "epoch: 1  batch: 3150  loss: 0.02790011465549469  \u0007ccuracy: 99.27301587301588%\n",
            "epoch: 1  batch: 3200  loss: 0.04778433218598366  \u0007ccuracy: 99.275%\n",
            "epoch: 1  batch: 3250  loss: 1.0943235793092754e-05  \u0007ccuracy: 99.27692307692308%\n",
            "epoch: 1  batch: 3300  loss: 0.003269138978794217  \u0007ccuracy: 99.27878787878788%\n",
            "epoch: 1  batch: 3350  loss: 2.5674899006844498e-05  \u0007ccuracy: 99.2865671641791%\n",
            "epoch: 1  batch: 3400  loss: 0.00034090527333319187  \u0007ccuracy: 99.28823529411764%\n",
            "epoch: 1  batch: 3450  loss: 0.0010072396835312247  \u0007ccuracy: 99.28695652173913%\n",
            "epoch: 1  batch: 3500  loss: 1.9084744053543545e-05  \u0007ccuracy: 99.29142857142857%\n",
            "epoch: 1  batch: 3550  loss: 3.448424467933364e-05  \u0007ccuracy: 99.29859154929578%\n",
            "epoch: 1  batch: 3600  loss: 0.0011643037432804704  \u0007ccuracy: 99.30277777777778%\n",
            "epoch: 1  batch: 3650  loss: 0.0017546511953696609  \u0007ccuracy: 99.2904109589041%\n",
            "epoch: 1  batch: 3700  loss: 0.0495271235704422  \u0007ccuracy: 99.28918918918919%\n",
            "epoch: 1  batch: 3750  loss: 0.00010184939310420305  \u0007ccuracy: 99.28266666666667%\n",
            "epoch: 1  batch: 3800  loss: 0.0003167811955790967  \u0007ccuracy: 99.28157894736842%\n",
            "epoch: 1  batch: 3850  loss: 1.5723364413133822e-05  \u0007ccuracy: 99.28571428571429%\n",
            "epoch: 1  batch: 3900  loss: 0.00851780828088522  \u0007ccuracy: 99.28717948717949%\n",
            "epoch: 1  batch: 3950  loss: 0.023941008374094963  \u0007ccuracy: 99.29620253164558%\n",
            "epoch: 1  batch: 4000  loss: 0.00011591615475481376  \u0007ccuracy: 99.2925%\n",
            "epoch: 1  batch: 4050  loss: 0.00034752037026919425  \u0007ccuracy: 99.29629629629629%\n",
            "epoch: 1  batch: 4100  loss: 0.0009041602606885135  \u0007ccuracy: 99.29268292682927%\n",
            "epoch: 1  batch: 4150  loss: 0.00015186038217507303  \u0007ccuracy: 99.29638554216868%\n",
            "epoch: 1  batch: 4200  loss: 0.12908890843391418  \u0007ccuracy: 99.3%\n",
            "epoch: 1  batch: 4250  loss: 0.1908218264579773  \u0007ccuracy: 99.2870588235294%\n",
            "epoch: 1  batch: 4300  loss: 0.008775850757956505  \u0007ccuracy: 99.27906976744185%\n",
            "epoch: 1  batch: 4350  loss: 0.0025685972068458796  \u0007ccuracy: 99.2735632183908%\n",
            "epoch: 1  batch: 4400  loss: 0.00013905097148381174  \u0007ccuracy: 99.27727272727273%\n",
            "epoch: 1  batch: 4450  loss: 0.0068732500076293945  \u0007ccuracy: 99.27865168539326%\n",
            "epoch: 1  batch: 4500  loss: 0.00016545355902053416  \u0007ccuracy: 99.27333333333333%\n",
            "epoch: 1  batch: 4550  loss: 0.002314568730071187  \u0007ccuracy: 99.26813186813187%\n",
            "epoch: 1  batch: 4600  loss: 0.0016652315389364958  \u0007ccuracy: 99.2695652173913%\n",
            "epoch: 1  batch: 4650  loss: 0.7434033155441284  \u0007ccuracy: 99.26451612903226%\n",
            "epoch: 1  batch: 4700  loss: 6.387801113305613e-05  \u0007ccuracy: 99.2595744680851%\n",
            "epoch: 1  batch: 4750  loss: 0.001527613727375865  \u0007ccuracy: 99.26315789473684%\n",
            "epoch: 1  batch: 4800  loss: 0.0029039906803518534  \u0007ccuracy: 99.26875%\n",
            "epoch: 1  batch: 4850  loss: 0.0007010147674009204  \u0007ccuracy: 99.2659793814433%\n",
            "epoch: 1  batch: 4900  loss: 0.0023938114754855633  \u0007ccuracy: 99.26938775510204%\n",
            "epoch: 1  batch: 4950  loss: 8.996025280794129e-05  \u0007ccuracy: 99.27070707070708%\n",
            "epoch: 1  batch: 5000  loss: 2.549783130234573e-05  \u0007ccuracy: 99.264%\n",
            "epoch: 1  batch: 5050  loss: 0.422842800617218  \u0007ccuracy: 99.26138613861386%\n",
            "epoch: 1  batch: 5100  loss: 0.008431527763605118  \u0007ccuracy: 99.25686274509803%\n",
            "epoch: 1  batch: 5150  loss: 0.23101632297039032  \u0007ccuracy: 99.25631067961164%\n",
            "epoch: 1  batch: 5200  loss: 0.0004094559117220342  \u0007ccuracy: 99.25576923076923%\n",
            "epoch: 1  batch: 5250  loss: 0.013523681089282036  \u0007ccuracy: 99.26095238095238%\n",
            "epoch: 1  batch: 5300  loss: 9.047823368746322e-06  \u0007ccuracy: 99.2622641509434%\n",
            "epoch: 1  batch: 5350  loss: 0.004226262681186199  \u0007ccuracy: 99.26168224299066%\n",
            "epoch: 1  batch: 5400  loss: 1.107423577195732e-05  \u0007ccuracy: 99.26666666666667%\n",
            "epoch: 1  batch: 5450  loss: 0.00048028226592577994  \u0007ccuracy: 99.2697247706422%\n",
            "epoch: 1  batch: 5500  loss: 0.03454681858420372  \u0007ccuracy: 99.27272727272727%\n",
            "epoch: 1  batch: 5550  loss: 0.00047819240717217326  \u0007ccuracy: 99.26306306306306%\n",
            "epoch: 1  batch: 5600  loss: 0.00016487675020471215  \u0007ccuracy: 99.26071428571429%\n",
            "epoch: 1  batch: 5650  loss: 0.0006649856804870069  \u0007ccuracy: 99.26548672566372%\n",
            "epoch: 1  batch: 5700  loss: 0.0001823803613660857  \u0007ccuracy: 99.25964912280702%\n",
            "epoch: 1  batch: 5750  loss: 6.079520517232595e-06  \u0007ccuracy: 99.26086956521739%\n",
            "epoch: 1  batch: 5800  loss: 0.0008764932863414288  \u0007ccuracy: 99.25862068965517%\n",
            "epoch: 1  batch: 5850  loss: 3.158742401865311e-05  \u0007ccuracy: 99.25470085470086%\n",
            "epoch: 1  batch: 5900  loss: 0.3700255751609802  \u0007ccuracy: 99.24745762711865%\n",
            "epoch: 1  batch: 5950  loss: 0.0019104976672679186  \u0007ccuracy: 99.24369747899159%\n",
            "epoch: 1  batch: 6000  loss: 0.002627719659358263  \u0007ccuracy: 99.24166666666666%\n",
            "epoch: 2  batch: 50  loss: 0.010573344305157661  \u0007ccuracy: 99.8%\n",
            "epoch: 2  batch: 100  loss: 0.001051253406330943  \u0007ccuracy: 99.8%\n",
            "epoch: 2  batch: 150  loss: 0.00015512829122599214  \u0007ccuracy: 99.8%\n",
            "epoch: 2  batch: 200  loss: 0.002935082418844104  \u0007ccuracy: 99.8%\n",
            "epoch: 2  batch: 250  loss: 6.30379217909649e-05  \u0007ccuracy: 99.84%\n",
            "epoch: 2  batch: 300  loss: 0.0072828615084290504  \u0007ccuracy: 99.76666666666667%\n",
            "epoch: 2  batch: 350  loss: 0.26634299755096436  \u0007ccuracy: 99.68571428571428%\n",
            "epoch: 2  batch: 400  loss: 9.543885244056582e-05  \u0007ccuracy: 99.625%\n",
            "epoch: 2  batch: 450  loss: 0.0017841752851381898  \u0007ccuracy: 99.57777777777778%\n",
            "epoch: 2  batch: 500  loss: 0.10634001344442368  \u0007ccuracy: 99.54%\n",
            "epoch: 2  batch: 550  loss: 8.086665911832824e-05  \u0007ccuracy: 99.56363636363636%\n",
            "epoch: 2  batch: 600  loss: 6.616058271902148e-06  \u0007ccuracy: 99.58333333333333%\n",
            "epoch: 2  batch: 650  loss: 7.834972348064184e-05  \u0007ccuracy: 99.6%\n",
            "epoch: 2  batch: 700  loss: 0.006234449800103903  \u0007ccuracy: 99.58571428571429%\n",
            "epoch: 2  batch: 750  loss: 2.2898491806699894e-05  \u0007ccuracy: 99.56%\n",
            "epoch: 2  batch: 800  loss: 5.967389006400481e-05  \u0007ccuracy: 99.55%\n",
            "epoch: 2  batch: 850  loss: 0.012755255214869976  \u0007ccuracy: 99.55294117647058%\n",
            "epoch: 2  batch: 900  loss: 0.00023367980611510575  \u0007ccuracy: 99.55555555555556%\n",
            "epoch: 2  batch: 950  loss: 0.0023609905038028955  \u0007ccuracy: 99.57894736842105%\n",
            "epoch: 2  batch: 1000  loss: 0.00034057156881317496  \u0007ccuracy: 99.58%\n",
            "epoch: 2  batch: 1050  loss: 8.294601138914004e-05  \u0007ccuracy: 99.6%\n",
            "epoch: 2  batch: 1100  loss: 0.0024073724634945393  \u0007ccuracy: 99.56363636363636%\n",
            "epoch: 2  batch: 1150  loss: 0.8218189477920532  \u0007ccuracy: 99.55652173913043%\n",
            "epoch: 2  batch: 1200  loss: 6.296433275565505e-05  \u0007ccuracy: 99.55%\n",
            "epoch: 2  batch: 1250  loss: 7.235907105496153e-06  \u0007ccuracy: 99.552%\n",
            "epoch: 2  batch: 1300  loss: 0.0016047715907916427  \u0007ccuracy: 99.55384615384615%\n",
            "epoch: 2  batch: 1350  loss: 0.00015133179840631783  \u0007ccuracy: 99.54814814814814%\n",
            "epoch: 2  batch: 1400  loss: 0.00464217783883214  \u0007ccuracy: 99.54285714285714%\n",
            "epoch: 2  batch: 1450  loss: 4.302789966459386e-05  \u0007ccuracy: 99.53793103448275%\n",
            "epoch: 2  batch: 1500  loss: 0.08175323158502579  \u0007ccuracy: 99.51333333333334%\n",
            "epoch: 2  batch: 1550  loss: 0.008345247246325016  \u0007ccuracy: 99.50322580645161%\n",
            "epoch: 2  batch: 1600  loss: 1.877417162177153e-05  \u0007ccuracy: 99.5%\n",
            "epoch: 2  batch: 1650  loss: 0.03227106109261513  \u0007ccuracy: 99.48484848484848%\n",
            "epoch: 2  batch: 1700  loss: 0.0006794902146793902  \u0007ccuracy: 99.47647058823529%\n",
            "epoch: 2  batch: 1750  loss: 1.6319127098540775e-05  \u0007ccuracy: 99.46285714285715%\n",
            "epoch: 2  batch: 1800  loss: 0.0013143416726961732  \u0007ccuracy: 99.46666666666667%\n",
            "epoch: 2  batch: 1850  loss: 2.295892954862211e-05  \u0007ccuracy: 99.47027027027028%\n",
            "epoch: 2  batch: 1900  loss: 0.00019769374921452254  \u0007ccuracy: 99.47368421052632%\n",
            "epoch: 2  batch: 1950  loss: 0.0005402140086516738  \u0007ccuracy: 99.47179487179487%\n",
            "epoch: 2  batch: 2000  loss: 4.3625375838018954e-05  \u0007ccuracy: 99.475%\n",
            "epoch: 2  batch: 2050  loss: 0.00026331451954320073  \u0007ccuracy: 99.4829268292683%\n",
            "epoch: 2  batch: 2100  loss: 0.007719260640442371  \u0007ccuracy: 99.47619047619048%\n",
            "epoch: 2  batch: 2150  loss: 0.004677309654653072  \u0007ccuracy: 99.47441860465116%\n",
            "epoch: 2  batch: 2200  loss: 8.255420834757388e-05  \u0007ccuracy: 99.48636363636363%\n",
            "epoch: 2  batch: 2250  loss: 3.0098686693236232e-05  \u0007ccuracy: 99.48%\n",
            "epoch: 2  batch: 2300  loss: 7.733400707365945e-05  \u0007ccuracy: 99.47826086956522%\n",
            "epoch: 2  batch: 2350  loss: 0.00010775524424389005  \u0007ccuracy: 99.48085106382979%\n",
            "epoch: 2  batch: 2400  loss: 1.1801697610280826e-06  \u0007ccuracy: 99.4875%\n",
            "epoch: 2  batch: 2450  loss: 5.00678481785144e-07  \u0007ccuracy: 99.48979591836735%\n",
            "epoch: 2  batch: 2500  loss: 0.12985503673553467  \u0007ccuracy: 99.488%\n",
            "epoch: 2  batch: 2550  loss: 0.00022352044470608234  \u0007ccuracy: 99.48235294117647%\n",
            "epoch: 2  batch: 2600  loss: 5.684377538273111e-05  \u0007ccuracy: 99.46923076923076%\n",
            "epoch: 2  batch: 2650  loss: 0.0001291941007366404  \u0007ccuracy: 99.47169811320755%\n",
            "epoch: 2  batch: 2700  loss: 0.0008492544293403625  \u0007ccuracy: 99.45925925925926%\n",
            "epoch: 2  batch: 2750  loss: 0.0001701181463431567  \u0007ccuracy: 99.46909090909091%\n",
            "epoch: 2  batch: 2800  loss: 8.639348379801959e-05  \u0007ccuracy: 99.46071428571429%\n",
            "epoch: 2  batch: 2850  loss: 6.914131631674536e-07  \u0007ccuracy: 99.45614035087719%\n",
            "epoch: 2  batch: 2900  loss: 9.491144737694412e-05  \u0007ccuracy: 99.45517241379311%\n",
            "epoch: 2  batch: 2950  loss: 0.013702595606446266  \u0007ccuracy: 99.46440677966102%\n",
            "epoch: 2  batch: 3000  loss: 0.005594036541879177  \u0007ccuracy: 99.46333333333334%\n",
            "epoch: 2  batch: 3050  loss: 0.002426102291792631  \u0007ccuracy: 99.46229508196721%\n",
            "epoch: 2  batch: 3100  loss: 0.00017038318037521094  \u0007ccuracy: 99.45806451612903%\n",
            "epoch: 2  batch: 3150  loss: 3.7034515116829425e-05  \u0007ccuracy: 99.46349206349207%\n",
            "epoch: 2  batch: 3200  loss: 0.00022160816297400743  \u0007ccuracy: 99.465625%\n",
            "epoch: 2  batch: 3250  loss: 0.06597794592380524  \u0007ccuracy: 99.46461538461539%\n",
            "epoch: 2  batch: 3300  loss: 0.0004955813055858016  \u0007ccuracy: 99.45454545454545%\n",
            "epoch: 2  batch: 3350  loss: 9.071496606338769e-05  \u0007ccuracy: 99.46268656716418%\n",
            "epoch: 2  batch: 3400  loss: 0.014087066054344177  \u0007ccuracy: 99.46176470588236%\n",
            "epoch: 2  batch: 3450  loss: 0.00031429147929884493  \u0007ccuracy: 99.45507246376812%\n",
            "epoch: 2  batch: 3500  loss: 0.0010482525685802102  \u0007ccuracy: 99.45428571428572%\n",
            "epoch: 2  batch: 3550  loss: 0.0026717130094766617  \u0007ccuracy: 99.45352112676056%\n",
            "epoch: 2  batch: 3600  loss: 0.003791452618315816  \u0007ccuracy: 99.44722222222222%\n",
            "epoch: 2  batch: 3650  loss: 0.0008483935962431133  \u0007ccuracy: 99.44931506849315%\n",
            "epoch: 2  batch: 3700  loss: 0.0030564770568162203  \u0007ccuracy: 99.44594594594595%\n",
            "epoch: 2  batch: 3750  loss: 0.0002752628060989082  \u0007ccuracy: 99.44%\n",
            "epoch: 2  batch: 3800  loss: 1.4948283433914185  \u0007ccuracy: 99.4342105263158%\n",
            "epoch: 2  batch: 3850  loss: 0.0004332537646405399  \u0007ccuracy: 99.43636363636364%\n",
            "epoch: 2  batch: 3900  loss: 0.046434614807367325  \u0007ccuracy: 99.43846153846154%\n",
            "epoch: 2  batch: 3950  loss: 0.04743271321058273  \u0007ccuracy: 99.44050632911393%\n",
            "epoch: 2  batch: 4000  loss: 8.935971709433943e-05  \u0007ccuracy: 99.435%\n",
            "epoch: 2  batch: 4050  loss: 0.0027690057177096605  \u0007ccuracy: 99.4320987654321%\n",
            "epoch: 2  batch: 4100  loss: 0.0023434844333678484  \u0007ccuracy: 99.43170731707318%\n",
            "epoch: 2  batch: 4150  loss: 0.030084261670708656  \u0007ccuracy: 99.43132530120482%\n",
            "epoch: 2  batch: 4200  loss: 0.0019320512656122446  \u0007ccuracy: 99.43333333333334%\n",
            "epoch: 2  batch: 4250  loss: 0.009111825376749039  \u0007ccuracy: 99.4235294117647%\n",
            "epoch: 2  batch: 4300  loss: 0.002035356592386961  \u0007ccuracy: 99.42558139534884%\n",
            "epoch: 2  batch: 4350  loss: 7.861587801016867e-05  \u0007ccuracy: 99.42758620689655%\n",
            "epoch: 2  batch: 4400  loss: 0.00012071266246493906  \u0007ccuracy: 99.42727272727272%\n",
            "epoch: 2  batch: 4450  loss: 1.650941339903511e-05  \u0007ccuracy: 99.4247191011236%\n",
            "epoch: 2  batch: 4500  loss: 0.00016201019752770662  \u0007ccuracy: 99.42888888888889%\n",
            "epoch: 2  batch: 4550  loss: 0.00022850188543088734  \u0007ccuracy: 99.42417582417582%\n",
            "epoch: 2  batch: 4600  loss: 1.419743330188794e-05  \u0007ccuracy: 99.42173913043479%\n",
            "epoch: 2  batch: 4650  loss: 3.004064183187438e-06  \u0007ccuracy: 99.4279569892473%\n",
            "epoch: 2  batch: 4700  loss: 0.0004885451053269207  \u0007ccuracy: 99.42978723404255%\n",
            "epoch: 2  batch: 4750  loss: 0.004883351735770702  \u0007ccuracy: 99.43368421052631%\n",
            "epoch: 2  batch: 4800  loss: 0.0525779202580452  \u0007ccuracy: 99.43125%\n",
            "epoch: 2  batch: 4850  loss: 0.0003233992320019752  \u0007ccuracy: 99.43505154639175%\n",
            "epoch: 2  batch: 4900  loss: 5.316688202583464e-06  \u0007ccuracy: 99.43061224489796%\n",
            "epoch: 2  batch: 4950  loss: 0.00019718808471225202  \u0007ccuracy: 99.43232323232323%\n",
            "epoch: 2  batch: 5000  loss: 3.2684318284736946e-05  \u0007ccuracy: 99.434%\n",
            "epoch: 2  batch: 5050  loss: 6.13570082350634e-05  \u0007ccuracy: 99.42970297029703%\n",
            "epoch: 2  batch: 5100  loss: 7.551445014541969e-05  \u0007ccuracy: 99.43333333333334%\n",
            "epoch: 2  batch: 5150  loss: 0.0025956775061786175  \u0007ccuracy: 99.4368932038835%\n",
            "epoch: 2  batch: 5200  loss: 0.4365256726741791  \u0007ccuracy: 99.43653846153846%\n",
            "epoch: 2  batch: 5250  loss: 0.006640697829425335  \u0007ccuracy: 99.44%\n",
            "epoch: 2  batch: 5300  loss: 4.565651124721626e-06  \u0007ccuracy: 99.44339622641509%\n",
            "epoch: 2  batch: 5350  loss: 0.00033318414352834225  \u0007ccuracy: 99.44485981308411%\n",
            "epoch: 2  batch: 5400  loss: 0.018467506393790245  \u0007ccuracy: 99.44444444444444%\n",
            "epoch: 2  batch: 5450  loss: 2.687844607862644e-05  \u0007ccuracy: 99.44770642201834%\n",
            "epoch: 2  batch: 5500  loss: 0.022635212168097496  \u0007ccuracy: 99.44545454545455%\n",
            "epoch: 2  batch: 5550  loss: 3.02528242173139e-05  \u0007ccuracy: 99.44864864864864%\n",
            "epoch: 2  batch: 5600  loss: 8.106204631985747e-07  \u0007ccuracy: 99.44464285714285%\n",
            "epoch: 2  batch: 5650  loss: 0.3150668740272522  \u0007ccuracy: 99.44070796460177%\n",
            "epoch: 2  batch: 5700  loss: 9.078823495656252e-05  \u0007ccuracy: 99.44035087719298%\n",
            "epoch: 2  batch: 5750  loss: 5.290889021125622e-05  \u0007ccuracy: 99.44347826086957%\n",
            "epoch: 2  batch: 5800  loss: 0.004615664482116699  \u0007ccuracy: 99.44310344827586%\n",
            "epoch: 2  batch: 5850  loss: 0.26740962266921997  \u0007ccuracy: 99.43418803418804%\n",
            "epoch: 2  batch: 5900  loss: 0.01470194011926651  \u0007ccuracy: 99.43389830508474%\n",
            "epoch: 2  batch: 5950  loss: 0.0004674163064919412  \u0007ccuracy: 99.43025210084033%\n",
            "epoch: 2  batch: 6000  loss: 0.0020512985065579414  \u0007ccuracy: 99.43166666666667%\n",
            "epoch: 3  batch: 50  loss: 0.00022634708147961646  \u0007ccuracy: 99.2%\n",
            "epoch: 3  batch: 100  loss: 0.37438592314720154  \u0007ccuracy: 99.3%\n",
            "epoch: 3  batch: 150  loss: 4.476707545109093e-05  \u0007ccuracy: 99.46666666666667%\n",
            "epoch: 3  batch: 200  loss: 4.160330718150362e-06  \u0007ccuracy: 99.45%\n",
            "epoch: 3  batch: 250  loss: 0.000197311193915084  \u0007ccuracy: 99.48%\n",
            "epoch: 3  batch: 300  loss: 0.0008230403764173388  \u0007ccuracy: 99.56666666666666%\n",
            "epoch: 3  batch: 350  loss: 0.006095025688409805  \u0007ccuracy: 99.48571428571428%\n",
            "epoch: 3  batch: 400  loss: 2.2565029212273657e-05  \u0007ccuracy: 99.475%\n",
            "epoch: 3  batch: 450  loss: 0.0032787795644253492  \u0007ccuracy: 99.46666666666667%\n",
            "epoch: 3  batch: 500  loss: 0.17677496373653412  \u0007ccuracy: 99.44%\n",
            "epoch: 3  batch: 550  loss: 0.007186059840023518  \u0007ccuracy: 99.38181818181818%\n",
            "epoch: 3  batch: 600  loss: 1.550834895169828e-05  \u0007ccuracy: 99.38333333333334%\n",
            "epoch: 3  batch: 650  loss: 2.2671043552691117e-05  \u0007ccuracy: 99.35384615384615%\n",
            "epoch: 3  batch: 700  loss: 0.0008135134121403098  \u0007ccuracy: 99.38571428571429%\n",
            "epoch: 3  batch: 750  loss: 2.580729778856039e-05  \u0007ccuracy: 99.38666666666667%\n",
            "epoch: 3  batch: 800  loss: 0.007551660295575857  \u0007ccuracy: 99.375%\n",
            "epoch: 3  batch: 850  loss: 0.0002904543071053922  \u0007ccuracy: 99.36470588235294%\n",
            "epoch: 3  batch: 900  loss: 5.3660965932067484e-05  \u0007ccuracy: 99.36666666666666%\n",
            "epoch: 3  batch: 950  loss: 1.3113017871546617e-07  \u0007ccuracy: 99.4%\n",
            "epoch: 3  batch: 1000  loss: 2.4318571831827285e-06  \u0007ccuracy: 99.41%\n",
            "epoch: 3  batch: 1050  loss: 1.175360921479296e-05  \u0007ccuracy: 99.42857142857143%\n",
            "epoch: 3  batch: 1100  loss: 0.0003635828907135874  \u0007ccuracy: 99.42727272727272%\n",
            "epoch: 3  batch: 1150  loss: 7.62937759191118e-07  \u0007ccuracy: 99.44347826086957%\n",
            "epoch: 3  batch: 1200  loss: 1.578259252710268e-05  \u0007ccuracy: 99.44166666666666%\n",
            "epoch: 3  batch: 1250  loss: 0.00019992876332253218  \u0007ccuracy: 99.456%\n",
            "epoch: 3  batch: 1300  loss: 3.0120398150756955e-05  \u0007ccuracy: 99.47692307692307%\n",
            "epoch: 3  batch: 1350  loss: 1.965702722372953e-05  \u0007ccuracy: 99.46666666666667%\n",
            "epoch: 3  batch: 1400  loss: 2.765631506917998e-06  \u0007ccuracy: 99.43571428571428%\n",
            "epoch: 3  batch: 1450  loss: 1.0788166036945768e-05  \u0007ccuracy: 99.42068965517241%\n",
            "epoch: 3  batch: 1500  loss: 0.00017962080892175436  \u0007ccuracy: 99.43333333333334%\n",
            "epoch: 3  batch: 1550  loss: 0.12701532244682312  \u0007ccuracy: 99.43225806451613%\n",
            "epoch: 3  batch: 1600  loss: 0.00010917248437181115  \u0007ccuracy: 99.425%\n",
            "epoch: 3  batch: 1650  loss: 0.0037270369939506054  \u0007ccuracy: 99.44242424242424%\n",
            "epoch: 3  batch: 1700  loss: 0.0033146075438708067  \u0007ccuracy: 99.45294117647059%\n",
            "epoch: 3  batch: 1750  loss: 0.00016414430865552276  \u0007ccuracy: 99.46285714285715%\n",
            "epoch: 3  batch: 1800  loss: 9.536727816339408e-07  \u0007ccuracy: 99.47222222222223%\n",
            "epoch: 3  batch: 1850  loss: 1.025151323119644e-05  \u0007ccuracy: 99.46486486486486%\n",
            "epoch: 3  batch: 1900  loss: 0.0010960655054077506  \u0007ccuracy: 99.47368421052632%\n",
            "epoch: 3  batch: 1950  loss: 1.7320171536994167e-05  \u0007ccuracy: 99.48205128205129%\n",
            "epoch: 3  batch: 2000  loss: 2.968274884551647e-06  \u0007ccuracy: 99.465%\n",
            "epoch: 3  batch: 2050  loss: 1.567568142490927e-05  \u0007ccuracy: 99.46341463414635%\n",
            "epoch: 3  batch: 2100  loss: 0.0010859898757189512  \u0007ccuracy: 99.47142857142858%\n",
            "epoch: 3  batch: 2150  loss: 0.004306180402636528  \u0007ccuracy: 99.48372093023256%\n",
            "epoch: 3  batch: 2200  loss: 0.00012769497698172927  \u0007ccuracy: 99.49545454545455%\n",
            "epoch: 3  batch: 2250  loss: 0.0005103049916215241  \u0007ccuracy: 99.49777777777778%\n",
            "epoch: 3  batch: 2300  loss: 4.2676047087297775e-06  \u0007ccuracy: 99.50434782608696%\n",
            "epoch: 3  batch: 2350  loss: 6.678320642095059e-05  \u0007ccuracy: 99.51489361702127%\n",
            "epoch: 3  batch: 2400  loss: 0.0017824862152338028  \u0007ccuracy: 99.50416666666666%\n",
            "epoch: 3  batch: 2450  loss: 2.8133270006946987e-06  \u0007ccuracy: 99.4938775510204%\n",
            "epoch: 3  batch: 2500  loss: 0.0002506208256818354  \u0007ccuracy: 99.496%\n",
            "epoch: 3  batch: 2550  loss: 0.00024200239568017423  \u0007ccuracy: 99.50196078431372%\n",
            "epoch: 3  batch: 2600  loss: 5.722038736166724e-07  \u0007ccuracy: 99.50384615384615%\n",
            "epoch: 3  batch: 2650  loss: 0.0037278980016708374  \u0007ccuracy: 99.5056603773585%\n",
            "epoch: 3  batch: 2700  loss: 7.123121031327173e-05  \u0007ccuracy: 99.5%\n",
            "epoch: 3  batch: 2750  loss: 0.0052764154970645905  \u0007ccuracy: 99.49818181818182%\n",
            "epoch: 3  batch: 2800  loss: 2.890462383220438e-05  \u0007ccuracy: 99.50357142857143%\n",
            "epoch: 3  batch: 2850  loss: 2.0955854779458605e-05  \u0007ccuracy: 99.50877192982456%\n",
            "epoch: 3  batch: 2900  loss: 0.0004595680511556566  \u0007ccuracy: 99.50689655172414%\n",
            "epoch: 3  batch: 2950  loss: 4.696785708802054e-06  \u0007ccuracy: 99.51186440677967%\n",
            "epoch: 3  batch: 3000  loss: 0.03344738110899925  \u0007ccuracy: 99.49%\n",
            "epoch: 3  batch: 3050  loss: 2.7130608941661194e-05  \u0007ccuracy: 99.49508196721311%\n",
            "epoch: 3  batch: 3100  loss: 0.027314916253089905  \u0007ccuracy: 99.48064516129033%\n",
            "epoch: 3  batch: 3150  loss: 0.0004267319163773209  \u0007ccuracy: 99.46984126984127%\n",
            "epoch: 3  batch: 3200  loss: 2.1694970200769603e-05  \u0007ccuracy: 99.471875%\n",
            "epoch: 3  batch: 3250  loss: 0.007476670201867819  \u0007ccuracy: 99.47384615384615%\n",
            "epoch: 3  batch: 3300  loss: 0.0005201250314712524  \u0007ccuracy: 99.47272727272727%\n",
            "epoch: 3  batch: 3350  loss: 1.8368475139141083e-05  \u0007ccuracy: 99.46865671641791%\n",
            "epoch: 3  batch: 3400  loss: 3.230549282307038e-06  \u0007ccuracy: 99.45882352941176%\n",
            "epoch: 3  batch: 3450  loss: 0.006987784989178181  \u0007ccuracy: 99.46376811594203%\n",
            "epoch: 3  batch: 3500  loss: 9.764043352333829e-05  \u0007ccuracy: 99.46857142857142%\n",
            "epoch: 3  batch: 3550  loss: 0.06571850180625916  \u0007ccuracy: 99.47323943661972%\n",
            "epoch: 3  batch: 3600  loss: 0.07095260173082352  \u0007ccuracy: 99.475%\n",
            "epoch: 3  batch: 3650  loss: 0.00016781898739282042  \u0007ccuracy: 99.47123287671234%\n",
            "epoch: 3  batch: 3700  loss: 0.0016797964926809072  \u0007ccuracy: 99.46756756756757%\n",
            "epoch: 3  batch: 3750  loss: 0.00037218540091998875  \u0007ccuracy: 99.46666666666667%\n",
            "epoch: 3  batch: 3800  loss: 4.875615559285507e-06  \u0007ccuracy: 99.46842105263158%\n",
            "epoch: 3  batch: 3850  loss: 3.06918409478385e-05  \u0007ccuracy: 99.47012987012987%\n",
            "epoch: 3  batch: 3900  loss: 0.00010506938997423276  \u0007ccuracy: 99.47435897435898%\n",
            "epoch: 3  batch: 3950  loss: 4.148437255935278e-06  \u0007ccuracy: 99.48101265822785%\n",
            "epoch: 3  batch: 4000  loss: 3.898118848155718e-06  \u0007ccuracy: 99.485%\n",
            "epoch: 3  batch: 4050  loss: 0.0003775662335101515  \u0007ccuracy: 99.4888888888889%\n",
            "epoch: 3  batch: 4100  loss: 1.8011731299338862e-05  \u0007ccuracy: 99.49268292682927%\n",
            "epoch: 3  batch: 4150  loss: 0.00011616064875852317  \u0007ccuracy: 99.49156626506024%\n",
            "epoch: 3  batch: 4200  loss: 0.010952755808830261  \u0007ccuracy: 99.47857142857143%\n",
            "epoch: 3  batch: 4250  loss: 0.00045086542377248406  \u0007ccuracy: 99.48%\n",
            "epoch: 3  batch: 4300  loss: 0.0006401977734640241  \u0007ccuracy: 99.47906976744186%\n",
            "epoch: 3  batch: 4350  loss: 4.386874479678227e-06  \u0007ccuracy: 99.47816091954023%\n",
            "epoch: 3  batch: 4400  loss: 0.006942742969840765  \u0007ccuracy: 99.47045454545454%\n",
            "epoch: 3  batch: 4450  loss: 0.003979557193815708  \u0007ccuracy: 99.46966292134832%\n",
            "epoch: 3  batch: 4500  loss: 0.3484647870063782  \u0007ccuracy: 99.46222222222222%\n",
            "epoch: 3  batch: 4550  loss: 0.1025150865316391  \u0007ccuracy: 99.45714285714286%\n",
            "epoch: 3  batch: 4600  loss: 0.008287380449473858  \u0007ccuracy: 99.45869565217392%\n",
            "epoch: 3  batch: 4650  loss: 8.845021511660889e-06  \u0007ccuracy: 99.46021505376343%\n",
            "epoch: 3  batch: 4700  loss: 2.395974843238946e-05  \u0007ccuracy: 99.45957446808511%\n",
            "epoch: 3  batch: 4750  loss: 0.000976571929641068  \u0007ccuracy: 99.45894736842105%\n",
            "epoch: 3  batch: 4800  loss: 0.00800163485109806  \u0007ccuracy: 99.45625%\n",
            "epoch: 3  batch: 4850  loss: 0.00012708235590253025  \u0007ccuracy: 99.45567010309279%\n",
            "epoch: 3  batch: 4900  loss: 2.9802129120071186e-06  \u0007ccuracy: 99.45918367346938%\n",
            "epoch: 3  batch: 4950  loss: 5.263520870357752e-05  \u0007ccuracy: 99.46464646464646%\n",
            "epoch: 3  batch: 5000  loss: 1.5115091628103983e-05  \u0007ccuracy: 99.46%\n",
            "epoch: 3  batch: 5050  loss: 0.008806148543953896  \u0007ccuracy: 99.45544554455445%\n",
            "epoch: 3  batch: 5100  loss: 5.792535375803709e-05  \u0007ccuracy: 99.45294117647059%\n",
            "epoch: 3  batch: 5150  loss: 7.700769856455736e-06  \u0007ccuracy: 99.4504854368932%\n",
            "epoch: 3  batch: 5200  loss: 0.002720785792917013  \u0007ccuracy: 99.45576923076923%\n",
            "epoch: 3  batch: 5250  loss: 0.012227066792547703  \u0007ccuracy: 99.46095238095238%\n",
            "epoch: 3  batch: 5300  loss: 0.0022104198578745127  \u0007ccuracy: 99.45471698113208%\n",
            "epoch: 3  batch: 5350  loss: 0.012333673425018787  \u0007ccuracy: 99.45420560747664%\n",
            "epoch: 3  batch: 5400  loss: 0.01310025341808796  \u0007ccuracy: 99.45%\n",
            "epoch: 3  batch: 5450  loss: 0.0002464359859004617  \u0007ccuracy: 99.44954128440367%\n",
            "epoch: 3  batch: 5500  loss: 0.00022274213552009314  \u0007ccuracy: 99.44727272727273%\n",
            "epoch: 3  batch: 5550  loss: 0.000948558677919209  \u0007ccuracy: 99.44864864864864%\n",
            "epoch: 3  batch: 5600  loss: 2.447230144753121e-05  \u0007ccuracy: 99.44821428571429%\n",
            "epoch: 3  batch: 5650  loss: 7.235918928927276e-06  \u0007ccuracy: 99.4424778761062%\n",
            "epoch: 3  batch: 5700  loss: 7.07851504557766e-05  \u0007ccuracy: 99.4421052631579%\n",
            "epoch: 3  batch: 5750  loss: 1.5091542081790976e-05  \u0007ccuracy: 99.44173913043478%\n",
            "epoch: 3  batch: 5800  loss: 0.0001254126545973122  \u0007ccuracy: 99.44310344827586%\n",
            "epoch: 3  batch: 5850  loss: 2.66880560957361e-05  \u0007ccuracy: 99.44444444444444%\n",
            "epoch: 3  batch: 5900  loss: 7.940132491057739e-05  \u0007ccuracy: 99.4457627118644%\n",
            "epoch: 3  batch: 5950  loss: 8.859594527166337e-05  \u0007ccuracy: 99.4453781512605%\n",
            "epoch: 3  batch: 6000  loss: 0.00010784013284137473  \u0007ccuracy: 99.44333333333333%\n",
            "epoch: 4  batch: 50  loss: 9.035878065333236e-06  \u0007ccuracy: 99.6%\n",
            "epoch: 4  batch: 100  loss: 4.0846323827281594e-05  \u0007ccuracy: 99.5%\n",
            "epoch: 4  batch: 150  loss: 7.072807784425095e-05  \u0007ccuracy: 99.53333333333333%\n",
            "epoch: 4  batch: 200  loss: 1.8154943973058835e-05  \u0007ccuracy: 99.5%\n",
            "epoch: 4  batch: 250  loss: 1.3732414117839653e-05  \u0007ccuracy: 99.48%\n",
            "epoch: 4  batch: 300  loss: 2.189706174249295e-05  \u0007ccuracy: 99.53333333333333%\n",
            "epoch: 4  batch: 350  loss: 0.009588615968823433  \u0007ccuracy: 99.6%\n",
            "epoch: 4  batch: 400  loss: 0.0005450561875477433  \u0007ccuracy: 99.625%\n",
            "epoch: 4  batch: 450  loss: 6.902043878653785e-06  \u0007ccuracy: 99.55555555555556%\n",
            "epoch: 4  batch: 500  loss: 0.0067018382251262665  \u0007ccuracy: 99.54%\n",
            "epoch: 4  batch: 550  loss: 0.0001247921900358051  \u0007ccuracy: 99.50909090909092%\n",
            "epoch: 4  batch: 600  loss: 0.03373446688055992  \u0007ccuracy: 99.53333333333333%\n",
            "epoch: 4  batch: 650  loss: 0.03508147597312927  \u0007ccuracy: 99.55384615384615%\n",
            "epoch: 4  batch: 700  loss: 4.637149231712101e-06  \u0007ccuracy: 99.55714285714286%\n",
            "epoch: 4  batch: 750  loss: 4.6729551286261994e-06  \u0007ccuracy: 99.58666666666667%\n",
            "epoch: 4  batch: 800  loss: 0.00031224702252075076  \u0007ccuracy: 99.575%\n",
            "epoch: 4  batch: 850  loss: 0.007266799919307232  \u0007ccuracy: 99.5764705882353%\n",
            "epoch: 4  batch: 900  loss: 0.006389821879565716  \u0007ccuracy: 99.56666666666666%\n",
            "epoch: 4  batch: 950  loss: 3.576278473360617e-08  \u0007ccuracy: 99.56842105263158%\n",
            "epoch: 4  batch: 1000  loss: 3.659669573607971e-06  \u0007ccuracy: 99.55%\n",
            "epoch: 4  batch: 1050  loss: 0.00010316209954908118  \u0007ccuracy: 99.54285714285714%\n",
            "epoch: 4  batch: 1100  loss: 2.1611580450553447e-05  \u0007ccuracy: 99.54545454545455%\n",
            "epoch: 4  batch: 1150  loss: 5.098474139231257e-05  \u0007ccuracy: 99.54782608695652%\n",
            "epoch: 4  batch: 1200  loss: 1.1884460946021136e-05  \u0007ccuracy: 99.55833333333334%\n",
            "epoch: 4  batch: 1250  loss: 4.631577030522749e-05  \u0007ccuracy: 99.568%\n",
            "epoch: 4  batch: 1300  loss: 8.344647994817933e-08  \u0007ccuracy: 99.57692307692308%\n",
            "epoch: 4  batch: 1350  loss: 0.0005364007083699107  \u0007ccuracy: 99.5925925925926%\n",
            "epoch: 4  batch: 1400  loss: 0.0044837212190032005  \u0007ccuracy: 99.59285714285714%\n",
            "epoch: 4  batch: 1450  loss: 0.0013393702683970332  \u0007ccuracy: 99.59310344827587%\n",
            "epoch: 4  batch: 1500  loss: 0.00010716042015701532  \u0007ccuracy: 99.59333333333333%\n",
            "epoch: 4  batch: 1550  loss: 0.00033474451629444957  \u0007ccuracy: 99.6%\n",
            "epoch: 4  batch: 1600  loss: 7.235760222101817e-06  \u0007ccuracy: 99.6125%\n",
            "epoch: 4  batch: 1650  loss: 0.00019914910080842674  \u0007ccuracy: 99.61212121212121%\n",
            "epoch: 4  batch: 1700  loss: 1.6628720914013684e-05  \u0007ccuracy: 99.6%\n",
            "epoch: 4  batch: 1750  loss: 0.0006952265975996852  \u0007ccuracy: 99.6%\n",
            "epoch: 4  batch: 1800  loss: 1.6689294568550395e-07  \u0007ccuracy: 99.61111111111111%\n",
            "epoch: 4  batch: 1850  loss: 0.0012271411251276731  \u0007ccuracy: 99.6054054054054%\n",
            "epoch: 4  batch: 1900  loss: 0.00013698312977794558  \u0007ccuracy: 99.61578947368422%\n",
            "epoch: 4  batch: 1950  loss: 5.722037030864158e-07  \u0007ccuracy: 99.61538461538461%\n",
            "epoch: 4  batch: 2000  loss: 1.1324823390168604e-06  \u0007ccuracy: 99.6%\n",
            "epoch: 4  batch: 2050  loss: 8.344646573732462e-08  \u0007ccuracy: 99.6%\n",
            "epoch: 4  batch: 2100  loss: 4.7899127821438015e-05  \u0007ccuracy: 99.5952380952381%\n",
            "epoch: 4  batch: 2150  loss: 1.4901082749929628e-06  \u0007ccuracy: 99.5906976744186%\n",
            "epoch: 4  batch: 2200  loss: 1.1014352821803186e-05  \u0007ccuracy: 99.58636363636364%\n",
            "epoch: 4  batch: 2250  loss: 9.360916737932712e-05  \u0007ccuracy: 99.58666666666667%\n",
            "epoch: 4  batch: 2300  loss: 0.008951482363045216  \u0007ccuracy: 99.59565217391304%\n",
            "epoch: 4  batch: 2350  loss: 0.0012035735417157412  \u0007ccuracy: 99.58723404255319%\n",
            "epoch: 4  batch: 2400  loss: 4.053054908581544e-06  \u0007ccuracy: 99.58333333333333%\n",
            "epoch: 4  batch: 2450  loss: 2.466185287630651e-05  \u0007ccuracy: 99.57551020408164%\n",
            "epoch: 4  batch: 2500  loss: 3.346843004692346e-05  \u0007ccuracy: 99.584%\n",
            "epoch: 4  batch: 2550  loss: 6.902103450556751e-06  \u0007ccuracy: 99.5764705882353%\n",
            "epoch: 4  batch: 2600  loss: 0.3813111186027527  \u0007ccuracy: 99.56153846153846%\n",
            "epoch: 4  batch: 2650  loss: 0.0006038216524757445  \u0007ccuracy: 99.55094339622642%\n",
            "epoch: 4  batch: 2700  loss: 0.0023275064304471016  \u0007ccuracy: 99.54814814814814%\n",
            "epoch: 4  batch: 2750  loss: 0.0004941172664985061  \u0007ccuracy: 99.54545454545455%\n",
            "epoch: 4  batch: 2800  loss: 0.001713297562673688  \u0007ccuracy: 99.53928571428571%\n",
            "epoch: 4  batch: 2850  loss: 0.4178234040737152  \u0007ccuracy: 99.54035087719298%\n",
            "epoch: 4  batch: 2900  loss: 4.995135896024294e-05  \u0007ccuracy: 99.54482758620689%\n",
            "epoch: 4  batch: 2950  loss: 0.03629998490214348  \u0007ccuracy: 99.54237288135593%\n",
            "epoch: 4  batch: 3000  loss: 0.006310794502496719  \u0007ccuracy: 99.54%\n",
            "epoch: 4  batch: 3050  loss: 0.0002317682810826227  \u0007ccuracy: 99.53114754098361%\n",
            "epoch: 4  batch: 3100  loss: 4.148448169871699e-06  \u0007ccuracy: 99.53225806451613%\n",
            "epoch: 4  batch: 3150  loss: 0.0003094075946137309  \u0007ccuracy: 99.53968253968254%\n",
            "epoch: 4  batch: 3200  loss: 6.210223364178091e-05  \u0007ccuracy: 99.5375%\n",
            "epoch: 4  batch: 3250  loss: 2.861021357603022e-07  \u0007ccuracy: 99.5323076923077%\n",
            "epoch: 4  batch: 3300  loss: 0.00039829578599892557  \u0007ccuracy: 99.52727272727273%\n",
            "epoch: 4  batch: 3350  loss: 5.018633146391949e-06  \u0007ccuracy: 99.51940298507462%\n",
            "epoch: 4  batch: 3400  loss: 0.001263693906366825  \u0007ccuracy: 99.52058823529411%\n",
            "epoch: 4  batch: 3450  loss: 2.1765270503237844e-05  \u0007ccuracy: 99.52463768115942%\n",
            "epoch: 4  batch: 3500  loss: 6.128640234237537e-05  \u0007ccuracy: 99.51428571428572%\n",
            "epoch: 4  batch: 3550  loss: 6.916526763234288e-05  \u0007ccuracy: 99.51830985915493%\n",
            "epoch: 4  batch: 3600  loss: 1.192092824453539e-08  \u0007ccuracy: 99.51944444444445%\n",
            "epoch: 4  batch: 3650  loss: 1.4185852705850266e-06  \u0007ccuracy: 99.52328767123288%\n",
            "epoch: 4  batch: 3700  loss: 0.05859023332595825  \u0007ccuracy: 99.52432432432433%\n",
            "epoch: 4  batch: 3750  loss: 4.196080226392951e-06  \u0007ccuracy: 99.52533333333334%\n",
            "epoch: 4  batch: 3800  loss: 2.337480145797599e-05  \u0007ccuracy: 99.52105263157895%\n",
            "epoch: 4  batch: 3850  loss: 3.11811309074983e-05  \u0007ccuracy: 99.52467532467533%\n",
            "epoch: 4  batch: 3900  loss: 0.00039318035123869777  \u0007ccuracy: 99.53076923076924%\n",
            "epoch: 4  batch: 3950  loss: 0.002126259496435523  \u0007ccuracy: 99.53417721518987%\n",
            "epoch: 4  batch: 4000  loss: 0.0010551511077210307  \u0007ccuracy: 99.54%\n",
            "epoch: 4  batch: 4050  loss: 7.748463758616708e-06  \u0007ccuracy: 99.54320987654322%\n",
            "epoch: 4  batch: 4100  loss: 0.0037077409215271473  \u0007ccuracy: 99.54634146341463%\n",
            "epoch: 4  batch: 4150  loss: 0.25370216369628906  \u0007ccuracy: 99.54939759036145%\n",
            "epoch: 4  batch: 4200  loss: 0.000231889498536475  \u0007ccuracy: 99.54523809523809%\n",
            "epoch: 4  batch: 4250  loss: 1.5103176338016056e-05  \u0007ccuracy: 99.54823529411765%\n",
            "epoch: 4  batch: 4300  loss: 0.00020611172658391297  \u0007ccuracy: 99.54651162790698%\n",
            "epoch: 4  batch: 4350  loss: 4.913227166980505e-05  \u0007ccuracy: 99.54482758620689%\n",
            "epoch: 4  batch: 4400  loss: 0.0002845640410669148  \u0007ccuracy: 99.54772727272727%\n",
            "epoch: 4  batch: 4450  loss: 0.0006376825622282922  \u0007ccuracy: 99.5438202247191%\n",
            "epoch: 4  batch: 4500  loss: 2.5510621526336763e-06  \u0007ccuracy: 99.54444444444445%\n",
            "epoch: 4  batch: 4550  loss: 0.013975488021969795  \u0007ccuracy: 99.54725274725274%\n",
            "epoch: 4  batch: 4600  loss: 0.08950731158256531  \u0007ccuracy: 99.54347826086956%\n",
            "epoch: 4  batch: 4650  loss: 0.2971065938472748  \u0007ccuracy: 99.54193548387097%\n",
            "epoch: 4  batch: 4700  loss: 1.323221113125328e-06  \u0007ccuracy: 99.54042553191489%\n",
            "epoch: 4  batch: 4750  loss: 0.001504478044807911  \u0007ccuracy: 99.53473684210526%\n",
            "epoch: 4  batch: 4800  loss: 2.7179557946510613e-06  \u0007ccuracy: 99.53541666666666%\n",
            "epoch: 4  batch: 4850  loss: 0.17689856886863708  \u0007ccuracy: 99.5340206185567%\n",
            "epoch: 4  batch: 4900  loss: 5.292824880598346e-06  \u0007ccuracy: 99.5326530612245%\n",
            "epoch: 4  batch: 4950  loss: 1.49598181451438e-05  \u0007ccuracy: 99.53131313131313%\n",
            "epoch: 4  batch: 5000  loss: 0.01869107410311699  \u0007ccuracy: 99.534%\n",
            "epoch: 4  batch: 5050  loss: 0.023030128329992294  \u0007ccuracy: 99.53465346534654%\n",
            "epoch: 4  batch: 5100  loss: 0.007708456367254257  \u0007ccuracy: 99.53333333333333%\n",
            "epoch: 4  batch: 5150  loss: 5.447754119813908e-06  \u0007ccuracy: 99.5359223300971%\n",
            "epoch: 4  batch: 5200  loss: 0.00022561119112651795  \u0007ccuracy: 99.54038461538461%\n",
            "epoch: 4  batch: 5250  loss: 0.42799538373947144  \u0007ccuracy: 99.54095238095238%\n",
            "epoch: 4  batch: 5300  loss: 0.0008930841577239335  \u0007ccuracy: 99.54150943396226%\n",
            "epoch: 4  batch: 5350  loss: 4.381598409963772e-05  \u0007ccuracy: 99.54018691588784%\n",
            "epoch: 4  batch: 5400  loss: 2.84414563793689e-05  \u0007ccuracy: 99.53333333333333%\n",
            "epoch: 4  batch: 5450  loss: 6.982588820392266e-05  \u0007ccuracy: 99.5302752293578%\n",
            "epoch: 4  batch: 5500  loss: 9.695665357867256e-05  \u0007ccuracy: 99.52727272727273%\n",
            "epoch: 4  batch: 5550  loss: 0.00033446989255025983  \u0007ccuracy: 99.52972972972972%\n",
            "epoch: 4  batch: 5600  loss: 0.0015589639078825712  \u0007ccuracy: 99.52857142857142%\n",
            "epoch: 4  batch: 5650  loss: 0.0007483033696189523  \u0007ccuracy: 99.52743362831859%\n",
            "epoch: 4  batch: 5700  loss: 0.3898639678955078  \u0007ccuracy: 99.52982456140352%\n",
            "epoch: 4  batch: 5750  loss: 1.6652633348712698e-05  \u0007ccuracy: 99.53217391304348%\n",
            "epoch: 4  batch: 5800  loss: 0.027261074632406235  \u0007ccuracy: 99.53448275862068%\n",
            "epoch: 4  batch: 5850  loss: 0.02981731854379177  \u0007ccuracy: 99.53504273504274%\n",
            "epoch: 4  batch: 5900  loss: 0.005548800807446241  \u0007ccuracy: 99.53389830508475%\n",
            "epoch: 4  batch: 5950  loss: 0.002485075267031789  \u0007ccuracy: 99.53445378151261%\n",
            "epoch: 4  batch: 6000  loss: 2.1457660182022664e-07  \u0007ccuracy: 99.53666666666666%\n",
            "epoch: 5  batch: 50  loss: 0.0042736828327178955  \u0007ccuracy: 99.8%\n",
            "epoch: 5  batch: 100  loss: 7.473734149243683e-05  \u0007ccuracy: 99.9%\n",
            "epoch: 5  batch: 150  loss: 9.630302520236e-05  \u0007ccuracy: 99.86666666666666%\n",
            "epoch: 5  batch: 200  loss: 0.002434016205370426  \u0007ccuracy: 99.85%\n",
            "epoch: 5  batch: 250  loss: 0.002982744248583913  \u0007ccuracy: 99.72%\n",
            "epoch: 5  batch: 300  loss: 0.000709730084054172  \u0007ccuracy: 99.76666666666667%\n",
            "epoch: 5  batch: 350  loss: 0.3410220146179199  \u0007ccuracy: 99.68571428571428%\n",
            "epoch: 5  batch: 400  loss: 0.049433913081884384  \u0007ccuracy: 99.725%\n",
            "epoch: 5  batch: 450  loss: 2.5868137072393438e-06  \u0007ccuracy: 99.66666666666667%\n",
            "epoch: 5  batch: 500  loss: 4.887575641987496e-07  \u0007ccuracy: 99.66%\n",
            "epoch: 5  batch: 550  loss: 0.028089765459299088  \u0007ccuracy: 99.63636363636364%\n",
            "epoch: 5  batch: 600  loss: 0.0005323931691236794  \u0007ccuracy: 99.63333333333334%\n",
            "epoch: 5  batch: 650  loss: 1.815414725570008e-05  \u0007ccuracy: 99.66153846153846%\n",
            "epoch: 5  batch: 700  loss: 0.00034666660940274596  \u0007ccuracy: 99.65714285714286%\n",
            "epoch: 5  batch: 750  loss: 2.029955794569105e-05  \u0007ccuracy: 99.64%\n",
            "epoch: 5  batch: 800  loss: 0.0010286846663802862  \u0007ccuracy: 99.65%\n",
            "epoch: 5  batch: 850  loss: 1.898825757962186e-05  \u0007ccuracy: 99.6470588235294%\n",
            "epoch: 5  batch: 900  loss: 1.3648792446474545e-05  \u0007ccuracy: 99.65555555555555%\n",
            "epoch: 5  batch: 950  loss: 0.021087605506181717  \u0007ccuracy: 99.63157894736842%\n",
            "epoch: 5  batch: 1000  loss: 0.00011864308908116072  \u0007ccuracy: 99.64%\n",
            "epoch: 5  batch: 1050  loss: 0.0681210458278656  \u0007ccuracy: 99.62857142857143%\n",
            "epoch: 5  batch: 1100  loss: 0.00010962582018692046  \u0007ccuracy: 99.62727272727273%\n",
            "epoch: 5  batch: 1150  loss: 1.441159110981971e-05  \u0007ccuracy: 99.62608695652175%\n",
            "epoch: 5  batch: 1200  loss: 0.0005484704743139446  \u0007ccuracy: 99.63333333333334%\n",
            "epoch: 5  batch: 1250  loss: 9.130685066338629e-05  \u0007ccuracy: 99.64%\n",
            "epoch: 5  batch: 1300  loss: 1.8941374946734868e-05  \u0007ccuracy: 99.63076923076923%\n",
            "epoch: 5  batch: 1350  loss: 2.12649283639621e-05  \u0007ccuracy: 99.62962962962963%\n",
            "epoch: 5  batch: 1400  loss: 9.894345112115843e-07  \u0007ccuracy: 99.64285714285714%\n",
            "epoch: 5  batch: 1450  loss: 2.6606157916830853e-05  \u0007ccuracy: 99.63448275862069%\n",
            "epoch: 5  batch: 1500  loss: 0.06202982738614082  \u0007ccuracy: 99.64%\n",
            "epoch: 5  batch: 1550  loss: 0.0012441849103197455  \u0007ccuracy: 99.63225806451612%\n",
            "epoch: 5  batch: 1600  loss: 0.0008402575622312725  \u0007ccuracy: 99.63125%\n",
            "epoch: 5  batch: 1650  loss: 0.2050783634185791  \u0007ccuracy: 99.63636363636364%\n",
            "epoch: 5  batch: 1700  loss: 5.8291939240007196e-06  \u0007ccuracy: 99.6470588235294%\n",
            "epoch: 5  batch: 1750  loss: 4.1364783101016656e-06  \u0007ccuracy: 99.65142857142857%\n",
            "epoch: 5  batch: 1800  loss: 9.023931852425449e-06  \u0007ccuracy: 99.65%\n",
            "epoch: 5  batch: 1850  loss: 0.0024324620608240366  \u0007ccuracy: 99.65405405405406%\n",
            "epoch: 5  batch: 1900  loss: 0.0013733659870922565  \u0007ccuracy: 99.64736842105263%\n",
            "epoch: 5  batch: 1950  loss: 0.008591031655669212  \u0007ccuracy: 99.64102564102564%\n",
            "epoch: 5  batch: 2000  loss: 1.8440787243889645e-05  \u0007ccuracy: 99.615%\n",
            "epoch: 5  batch: 2050  loss: 0.0002724613877944648  \u0007ccuracy: 99.61463414634146%\n",
            "epoch: 5  batch: 2100  loss: 0.0021361676044762135  \u0007ccuracy: 99.6%\n",
            "epoch: 5  batch: 2150  loss: 3.6554807593347505e-05  \u0007ccuracy: 99.6046511627907%\n",
            "epoch: 5  batch: 2200  loss: 4.789874583366327e-05  \u0007ccuracy: 99.60909090909091%\n",
            "epoch: 5  batch: 2250  loss: 0.0016976287588477135  \u0007ccuracy: 99.61333333333333%\n",
            "epoch: 5  batch: 2300  loss: 0.0011485533323138952  \u0007ccuracy: 99.62173913043478%\n",
            "epoch: 5  batch: 2350  loss: 0.0001080549118341878  \u0007ccuracy: 99.62553191489361%\n",
            "epoch: 5  batch: 2400  loss: 1.2742671060550492e-05  \u0007ccuracy: 99.625%\n",
            "epoch: 5  batch: 2450  loss: 7.152556236178498e-08  \u0007ccuracy: 99.62448979591836%\n",
            "epoch: 5  batch: 2500  loss: 1.2981328836758621e-05  \u0007ccuracy: 99.624%\n",
            "epoch: 5  batch: 2550  loss: 1.5616387827321887e-06  \u0007ccuracy: 99.62352941176471%\n",
            "epoch: 5  batch: 2600  loss: 2.9802305334669654e-07  \u0007ccuracy: 99.61923076923077%\n",
            "epoch: 5  batch: 2650  loss: 1.311301929263209e-07  \u0007ccuracy: 99.62264150943396%\n",
            "epoch: 5  batch: 2700  loss: 8.872693433659151e-05  \u0007ccuracy: 99.62222222222222%\n",
            "epoch: 5  batch: 2750  loss: 1.5377881936728954e-06  \u0007ccuracy: 99.62545454545455%\n",
            "epoch: 5  batch: 2800  loss: 1.5258672192430822e-06  \u0007ccuracy: 99.62142857142857%\n",
            "epoch: 5  batch: 2850  loss: 6.520665920106694e-06  \u0007ccuracy: 99.60350877192982%\n",
            "epoch: 5  batch: 2900  loss: 0.001768570626154542  \u0007ccuracy: 99.59655172413792%\n",
            "epoch: 5  batch: 2950  loss: 0.0013961488148197532  \u0007ccuracy: 99.59661016949153%\n",
            "epoch: 5  batch: 3000  loss: 0.000920709571801126  \u0007ccuracy: 99.59333333333333%\n",
            "epoch: 5  batch: 3050  loss: 0.06141423434019089  \u0007ccuracy: 99.5967213114754%\n",
            "epoch: 5  batch: 3100  loss: 4.3909829400945455e-05  \u0007ccuracy: 99.59677419354838%\n",
            "epoch: 5  batch: 3150  loss: 0.00020292359113227576  \u0007ccuracy: 99.6%\n",
            "epoch: 5  batch: 3200  loss: 3.099438856679626e-07  \u0007ccuracy: 99.60625%\n",
            "epoch: 5  batch: 3250  loss: 0.00762174790725112  \u0007ccuracy: 99.60923076923076%\n",
            "epoch: 5  batch: 3300  loss: 4.76837058727142e-08  \u0007ccuracy: 99.61212121212121%\n",
            "epoch: 5  batch: 3350  loss: 5.87684598940541e-06  \u0007ccuracy: 99.61194029850746%\n",
            "epoch: 5  batch: 3400  loss: 6.318076088973612e-07  \u0007ccuracy: 99.61176470588235%\n",
            "epoch: 5  batch: 3450  loss: 1.7725960788084194e-05  \u0007ccuracy: 99.60579710144927%\n",
            "epoch: 5  batch: 3500  loss: 0.0011923146666958928  \u0007ccuracy: 99.60571428571428%\n",
            "epoch: 5  batch: 3550  loss: 8.945247100200504e-05  \u0007ccuracy: 99.60281690140845%\n",
            "epoch: 5  batch: 3600  loss: 2.66534807451535e-05  \u0007ccuracy: 99.59722222222223%\n",
            "epoch: 5  batch: 3650  loss: 6.866353942314163e-06  \u0007ccuracy: 99.6%\n",
            "epoch: 5  batch: 3700  loss: 0.010989496484398842  \u0007ccuracy: 99.6027027027027%\n",
            "epoch: 5  batch: 3750  loss: 3.4448301448719576e-05  \u0007ccuracy: 99.60266666666666%\n",
            "epoch: 5  batch: 3800  loss: 4.76837058727142e-08  \u0007ccuracy: 99.6%\n",
            "epoch: 5  batch: 3850  loss: 1.2302116374485195e-05  \u0007ccuracy: 99.6%\n",
            "epoch: 5  batch: 3900  loss: 0.00016761546430643648  \u0007ccuracy: 99.5974358974359%\n",
            "epoch: 5  batch: 3950  loss: 0.027890395373106003  \u0007ccuracy: 99.6%\n",
            "epoch: 5  batch: 4000  loss: 0.001099419896490872  \u0007ccuracy: 99.59%\n",
            "epoch: 5  batch: 4050  loss: 0.5340005159378052  \u0007ccuracy: 99.58765432098765%\n",
            "epoch: 5  batch: 4100  loss: 7.336105045396835e-05  \u0007ccuracy: 99.59024390243903%\n",
            "epoch: 5  batch: 4150  loss: 0.004630047827959061  \u0007ccuracy: 99.58554216867469%\n",
            "epoch: 5  batch: 4200  loss: 0.0  \u0007ccuracy: 99.58571428571429%\n",
            "epoch: 5  batch: 4250  loss: 2.790304642985575e-05  \u0007ccuracy: 99.5835294117647%\n",
            "epoch: 5  batch: 4300  loss: 5.006683750252705e-06  \u0007ccuracy: 99.58837209302325%\n",
            "epoch: 5  batch: 4350  loss: 2.7656215024762787e-06  \u0007ccuracy: 99.58850574712643%\n",
            "epoch: 5  batch: 4400  loss: 8.583050430388539e-07  \u0007ccuracy: 99.58636363636364%\n",
            "epoch: 5  batch: 4450  loss: 2.2195124984136783e-05  \u0007ccuracy: 99.58651685393258%\n",
            "epoch: 5  batch: 4500  loss: 0.12396808713674545  \u0007ccuracy: 99.58444444444444%\n",
            "epoch: 5  batch: 4550  loss: 2.384183801495965e-07  \u0007ccuracy: 99.58461538461539%\n",
            "epoch: 5  batch: 4600  loss: 0.001446065492928028  \u0007ccuracy: 99.5891304347826%\n",
            "epoch: 5  batch: 4650  loss: 5.960452540421102e-07  \u0007ccuracy: 99.59139784946237%\n",
            "epoch: 5  batch: 4700  loss: 0.011465495452284813  \u0007ccuracy: 99.59148936170213%\n",
            "epoch: 5  batch: 4750  loss: 0.0033384249545633793  \u0007ccuracy: 99.59368421052632%\n",
            "epoch: 5  batch: 4800  loss: 2.0980714907636866e-06  \u0007ccuracy: 99.5875%\n",
            "epoch: 5  batch: 4850  loss: 0.06270170956850052  \u0007ccuracy: 99.58762886597938%\n",
            "epoch: 5  batch: 4900  loss: 0.00044517102651298046  \u0007ccuracy: 99.58367346938776%\n",
            "epoch: 5  batch: 4950  loss: 0.02154524065554142  \u0007ccuracy: 99.57979797979797%\n",
            "epoch: 5  batch: 5000  loss: 0.005005573853850365  \u0007ccuracy: 99.584%\n",
            "epoch: 5  batch: 5050  loss: 0.04346083849668503  \u0007ccuracy: 99.58217821782178%\n",
            "epoch: 5  batch: 5100  loss: 6.264393596211448e-05  \u0007ccuracy: 99.58235294117647%\n",
            "epoch: 5  batch: 5150  loss: 0.0022319257259368896  \u0007ccuracy: 99.58252427184466%\n",
            "epoch: 5  batch: 5200  loss: 3.576278473360617e-08  \u0007ccuracy: 99.58653846153847%\n",
            "epoch: 5  batch: 5250  loss: 0.0001472921867389232  \u0007ccuracy: 99.58666666666667%\n",
            "epoch: 5  batch: 5300  loss: 0.0017192959785461426  \u0007ccuracy: 99.58301886792452%\n",
            "epoch: 5  batch: 5350  loss: 1.931178076119977e-06  \u0007ccuracy: 99.57943925233644%\n",
            "epoch: 5  batch: 5400  loss: 1.5258141502272338e-05  \u0007ccuracy: 99.58148148148148%\n",
            "epoch: 5  batch: 5450  loss: 0.017748817801475525  \u0007ccuracy: 99.57614678899083%\n",
            "epoch: 5  batch: 5500  loss: 0.0005560458521358669  \u0007ccuracy: 99.57454545454546%\n",
            "epoch: 5  batch: 5550  loss: 9.333791240351275e-06  \u0007ccuracy: 99.57477477477478%\n",
            "epoch: 5  batch: 5600  loss: 0.24997317790985107  \u0007ccuracy: 99.56785714285714%\n",
            "epoch: 5  batch: 5650  loss: 1.5139521565288305e-06  \u0007ccuracy: 99.56991150442478%\n",
            "epoch: 5  batch: 5700  loss: 0.01709451898932457  \u0007ccuracy: 99.56666666666666%\n",
            "epoch: 5  batch: 5750  loss: 5.811357914353721e-05  \u0007ccuracy: 99.56521739130434%\n",
            "epoch: 5  batch: 5800  loss: 1.0489911801414564e-05  \u0007ccuracy: 99.56551724137931%\n",
            "epoch: 5  batch: 5850  loss: 1.0311099686077796e-05  \u0007ccuracy: 99.56923076923077%\n",
            "epoch: 5  batch: 5900  loss: 0.0004845178627874702  \u0007ccuracy: 99.57118644067796%\n",
            "epoch: 5  batch: 5950  loss: 0.00023757775488775223  \u0007ccuracy: 99.56806722689076%\n",
            "epoch: 5  batch: 6000  loss: 0.00824105367064476  \u0007ccuracy: 99.56666666666666%\n",
            "epoch: 6  batch: 50  loss: 0.0009214716264978051  \u0007ccuracy: 99.8%\n",
            "epoch: 6  batch: 100  loss: 7.118727080523968e-05  \u0007ccuracy: 99.8%\n",
            "epoch: 6  batch: 150  loss: 3.7737110687885433e-05  \u0007ccuracy: 99.66666666666667%\n",
            "epoch: 6  batch: 200  loss: 0.029718970879912376  \u0007ccuracy: 99.7%\n",
            "epoch: 6  batch: 250  loss: 2.5973451556637883e-05  \u0007ccuracy: 99.72%\n",
            "epoch: 6  batch: 300  loss: 4.768370942542788e-08  \u0007ccuracy: 99.73333333333333%\n",
            "epoch: 6  batch: 350  loss: 0.0003164907975587994  \u0007ccuracy: 99.77142857142857%\n",
            "epoch: 6  batch: 400  loss: 0.0020158563274890184  \u0007ccuracy: 99.775%\n",
            "epoch: 6  batch: 450  loss: 2.384185471271394e-08  \u0007ccuracy: 99.77777777777777%\n",
            "epoch: 6  batch: 500  loss: 1.3232158835307928e-06  \u0007ccuracy: 99.74%\n",
            "epoch: 6  batch: 550  loss: 1.0728831512096804e-07  \u0007ccuracy: 99.72727272727273%\n",
            "epoch: 6  batch: 600  loss: 0.00020932868937961757  \u0007ccuracy: 99.71666666666667%\n",
            "epoch: 6  batch: 650  loss: 5.6503886298742145e-06  \u0007ccuracy: 99.67692307692307%\n",
            "epoch: 6  batch: 700  loss: 1.170570612885058e-05  \u0007ccuracy: 99.7%\n",
            "epoch: 6  batch: 750  loss: 0.05966233089566231  \u0007ccuracy: 99.70666666666666%\n",
            "epoch: 6  batch: 800  loss: 0.000626359018497169  \u0007ccuracy: 99.7%\n",
            "epoch: 6  batch: 850  loss: 0.00024957553250715137  \u0007ccuracy: 99.69411764705882%\n",
            "epoch: 6  batch: 900  loss: 0.0005873256595805287  \u0007ccuracy: 99.68888888888888%\n",
            "epoch: 6  batch: 950  loss: 0.007065669633448124  \u0007ccuracy: 99.70526315789473%\n",
            "epoch: 6  batch: 1000  loss: 7.0331007009372115e-06  \u0007ccuracy: 99.71%\n",
            "epoch: 6  batch: 1050  loss: 0.0001675756211625412  \u0007ccuracy: 99.6952380952381%\n",
            "epoch: 6  batch: 1100  loss: 9.059496733243577e-06  \u0007ccuracy: 99.7090909090909%\n",
            "epoch: 6  batch: 1150  loss: 3.6715834994538454e-06  \u0007ccuracy: 99.72173913043478%\n",
            "epoch: 6  batch: 1200  loss: 3.222900704713538e-05  \u0007ccuracy: 99.725%\n",
            "epoch: 6  batch: 1250  loss: 6.914355617482215e-05  \u0007ccuracy: 99.736%\n",
            "epoch: 6  batch: 1300  loss: 1.2874568255938357e-06  \u0007ccuracy: 99.73076923076923%\n",
            "epoch: 6  batch: 1350  loss: 0.3145877420902252  \u0007ccuracy: 99.71111111111111%\n",
            "epoch: 6  batch: 1400  loss: 0.0002168475475627929  \u0007ccuracy: 99.67857142857143%\n",
            "epoch: 6  batch: 1450  loss: 7.21203105058521e-06  \u0007ccuracy: 99.68275862068965%\n",
            "epoch: 6  batch: 1500  loss: 4.756370344694005e-06  \u0007ccuracy: 99.67333333333333%\n",
            "epoch: 6  batch: 1550  loss: 9.953791050065774e-06  \u0007ccuracy: 99.6774193548387%\n",
            "epoch: 6  batch: 1600  loss: 2.5365970941493288e-05  \u0007ccuracy: 99.66875%\n",
            "epoch: 6  batch: 1650  loss: 9.572176168148872e-06  \u0007ccuracy: 99.66666666666667%\n",
            "epoch: 6  batch: 1700  loss: 3.457064678968891e-07  \u0007ccuracy: 99.66470588235295%\n",
            "epoch: 6  batch: 1750  loss: 4.053113116242457e-07  \u0007ccuracy: 99.66285714285715%\n",
            "epoch: 6  batch: 1800  loss: 1.0132762326975353e-06  \u0007ccuracy: 99.67222222222222%\n",
            "epoch: 6  batch: 1850  loss: 0.0003215493925381452  \u0007ccuracy: 99.67027027027027%\n",
            "epoch: 6  batch: 1900  loss: 3.087480308749946e-06  \u0007ccuracy: 99.67368421052632%\n",
            "epoch: 6  batch: 1950  loss: 0.0005689028184860945  \u0007ccuracy: 99.67179487179487%\n",
            "epoch: 6  batch: 2000  loss: 4.768370942542788e-08  \u0007ccuracy: 99.68%\n",
            "epoch: 6  batch: 2050  loss: 1.5497195704483602e-07  \u0007ccuracy: 99.6829268292683%\n",
            "epoch: 6  batch: 2100  loss: 0.007456501480191946  \u0007ccuracy: 99.68571428571428%\n",
            "epoch: 6  batch: 2150  loss: 6.639813364017755e-06  \u0007ccuracy: 99.69302325581396%\n",
            "epoch: 6  batch: 2200  loss: 0.00041813572170212865  \u0007ccuracy: 99.67727272727272%\n",
            "epoch: 6  batch: 2250  loss: 8.082194653979968e-06  \u0007ccuracy: 99.64888888888889%\n",
            "epoch: 6  batch: 2300  loss: 1.549720280991096e-07  \u0007ccuracy: 99.64782608695653%\n",
            "epoch: 6  batch: 2350  loss: 1.00136399269104  \u0007ccuracy: 99.64255319148936%\n",
            "epoch: 6  batch: 2400  loss: 0.0007465780945494771  \u0007ccuracy: 99.6375%\n",
            "epoch: 6  batch: 2450  loss: 0.00067874975502491  \u0007ccuracy: 99.62448979591836%\n",
            "epoch: 6  batch: 2500  loss: 3.516644255796564e-06  \u0007ccuracy: 99.616%\n",
            "epoch: 6  batch: 2550  loss: 6.611704884562641e-05  \u0007ccuracy: 99.6078431372549%\n",
            "epoch: 6  batch: 2600  loss: 2.181514219046221e-06  \u0007ccuracy: 99.6076923076923%\n",
            "epoch: 6  batch: 2650  loss: 1.919252554216655e-06  \u0007ccuracy: 99.59622641509434%\n",
            "epoch: 6  batch: 2700  loss: 1.9073475243658322e-07  \u0007ccuracy: 99.58888888888889%\n",
            "epoch: 6  batch: 2750  loss: 0.003596259979531169  \u0007ccuracy: 99.58545454545454%\n",
            "epoch: 6  batch: 2800  loss: 0.0013002512278035283  \u0007ccuracy: 99.58214285714286%\n",
            "epoch: 6  batch: 2850  loss: 1.566360515425913e-05  \u0007ccuracy: 99.57894736842105%\n",
            "epoch: 6  batch: 2900  loss: 0.0140166524797678  \u0007ccuracy: 99.57586206896552%\n",
            "epoch: 6  batch: 2950  loss: 0.006677129305899143  \u0007ccuracy: 99.58305084745763%\n",
            "epoch: 6  batch: 3000  loss: 0.009340940974652767  \u0007ccuracy: 99.59%\n",
            "epoch: 6  batch: 3050  loss: 9.083601980819367e-06  \u0007ccuracy: 99.59344262295082%\n",
            "epoch: 6  batch: 3100  loss: 0.0003047192294616252  \u0007ccuracy: 99.59032258064516%\n",
            "epoch: 6  batch: 3150  loss: 3.8046542613301426e-05  \u0007ccuracy: 99.5904761904762%\n",
            "epoch: 6  batch: 3200  loss: 9.953668268281035e-06  \u0007ccuracy: 99.5875%\n",
            "epoch: 6  batch: 3250  loss: 0.00028840723098255694  \u0007ccuracy: 99.59384615384616%\n",
            "epoch: 6  batch: 3300  loss: 0.014113661833107471  \u0007ccuracy: 99.5969696969697%\n",
            "epoch: 6  batch: 3350  loss: 0.00015949025691952556  \u0007ccuracy: 99.6%\n",
            "epoch: 6  batch: 3400  loss: 0.008273706771433353  \u0007ccuracy: 99.59411764705882%\n",
            "epoch: 6  batch: 3450  loss: 0.0066757649183273315  \u0007ccuracy: 99.58840579710144%\n",
            "epoch: 6  batch: 3500  loss: 9.441146175959148e-06  \u0007ccuracy: 99.58857142857143%\n",
            "epoch: 6  batch: 3550  loss: 7.14050984242931e-05  \u0007ccuracy: 99.59436619718309%\n",
            "epoch: 6  batch: 3600  loss: 2.384185648907078e-08  \u0007ccuracy: 99.6%\n",
            "epoch: 6  batch: 3650  loss: 0.0006305275019258261  \u0007ccuracy: 99.6027397260274%\n",
            "epoch: 6  batch: 3700  loss: 3.2186488851948525e-07  \u0007ccuracy: 99.6%\n",
            "epoch: 6  batch: 3750  loss: 7.974820618983358e-06  \u0007ccuracy: 99.60266666666666%\n",
            "epoch: 6  batch: 3800  loss: 2.0265561317955871e-07  \u0007ccuracy: 99.60263157894737%\n",
            "epoch: 6  batch: 3850  loss: 0.0035970546305179596  \u0007ccuracy: 99.6%\n",
            "epoch: 6  batch: 3900  loss: 4.23966339440085e-05  \u0007ccuracy: 99.60512820512821%\n",
            "epoch: 6  batch: 3950  loss: 1.9431049622653518e-06  \u0007ccuracy: 99.61012658227848%\n",
            "epoch: 6  batch: 4000  loss: 1.1920858469238738e-06  \u0007ccuracy: 99.61%\n",
            "epoch: 6  batch: 4050  loss: 0.0023195284884423018  \u0007ccuracy: 99.61234567901235%\n",
            "epoch: 6  batch: 4100  loss: 8.425823762081563e-05  \u0007ccuracy: 99.60975609756098%\n",
            "epoch: 6  batch: 4150  loss: 0.0002447724691592157  \u0007ccuracy: 99.59759036144578%\n",
            "epoch: 6  batch: 4200  loss: 0.0001448845723643899  \u0007ccuracy: 99.60238095238095%\n",
            "epoch: 6  batch: 4250  loss: 4.545618867268786e-05  \u0007ccuracy: 99.60470588235295%\n",
            "epoch: 6  batch: 4300  loss: 0.0001362496695946902  \u0007ccuracy: 99.60697674418604%\n",
            "epoch: 6  batch: 4350  loss: 2.455683215885074e-06  \u0007ccuracy: 99.60689655172413%\n",
            "epoch: 6  batch: 4400  loss: 0.052690863609313965  \u0007ccuracy: 99.60909090909091%\n",
            "epoch: 6  batch: 4450  loss: 9.894131835608277e-06  \u0007ccuracy: 99.61123595505617%\n",
            "epoch: 6  batch: 4500  loss: 5.960300768492743e-06  \u0007ccuracy: 99.61111111111111%\n",
            "epoch: 6  batch: 4550  loss: 0.0009591482812538743  \u0007ccuracy: 99.61098901098902%\n",
            "epoch: 6  batch: 4600  loss: 0.00014490459579974413  \u0007ccuracy: 99.61304347826086%\n",
            "epoch: 6  batch: 4650  loss: 6.377581939887023e-06  \u0007ccuracy: 99.61290322580645%\n",
            "epoch: 6  batch: 4700  loss: 0.005674677435308695  \u0007ccuracy: 99.60851063829787%\n",
            "epoch: 6  batch: 4750  loss: 5.125927600602154e-06  \u0007ccuracy: 99.6042105263158%\n",
            "epoch: 6  batch: 4800  loss: 7.581453246530145e-06  \u0007ccuracy: 99.60416666666667%\n",
            "epoch: 6  batch: 4850  loss: 0.00019710433844011277  \u0007ccuracy: 99.60412371134021%\n",
            "epoch: 6  batch: 4900  loss: 0.006096585653722286  \u0007ccuracy: 99.59795918367347%\n",
            "epoch: 6  batch: 4950  loss: 5.722038736166724e-07  \u0007ccuracy: 99.5959595959596%\n",
            "epoch: 6  batch: 5000  loss: 3.3182666811626405e-05  \u0007ccuracy: 99.596%\n",
            "epoch: 6  batch: 5050  loss: 9.536741885085576e-08  \u0007ccuracy: 99.59603960396039%\n",
            "epoch: 6  batch: 5100  loss: 4.124607585254125e-06  \u0007ccuracy: 99.5921568627451%\n",
            "epoch: 6  batch: 5150  loss: 0.0007582300459034741  \u0007ccuracy: 99.59417475728155%\n",
            "epoch: 6  batch: 5200  loss: 4.1512375901220366e-05  \u0007ccuracy: 99.59038461538462%\n",
            "epoch: 6  batch: 5250  loss: 8.046508810366504e-06  \u0007ccuracy: 99.59238095238095%\n",
            "epoch: 6  batch: 5300  loss: 4.982889549864922e-06  \u0007ccuracy: 99.59622641509434%\n",
            "epoch: 6  batch: 5350  loss: 0.008170772343873978  \u0007ccuracy: 99.59439252336449%\n",
            "epoch: 6  batch: 5400  loss: 9.264661639463156e-05  \u0007ccuracy: 99.5925925925926%\n",
            "epoch: 6  batch: 5450  loss: 9.693698666524142e-05  \u0007ccuracy: 99.5908256880734%\n",
            "epoch: 6  batch: 5500  loss: 8.817829075269401e-05  \u0007ccuracy: 99.59272727272727%\n",
            "epoch: 6  batch: 5550  loss: 8.475509275740478e-06  \u0007ccuracy: 99.59279279279279%\n",
            "epoch: 6  batch: 5600  loss: 0.00010786323400679976  \u0007ccuracy: 99.59285714285714%\n",
            "epoch: 6  batch: 5650  loss: 2.5891236873576418e-05  \u0007ccuracy: 99.59469026548672%\n",
            "epoch: 6  batch: 5700  loss: 0.004900789819657803  \u0007ccuracy: 99.5982456140351%\n",
            "epoch: 6  batch: 5750  loss: 0.008439791388809681  \u0007ccuracy: 99.59478260869565%\n",
            "epoch: 6  batch: 5800  loss: 7.7127042459324e-06  \u0007ccuracy: 99.59137931034483%\n",
            "epoch: 6  batch: 5850  loss: 5.960463411724959e-08  \u0007ccuracy: 99.59316239316239%\n",
            "epoch: 6  batch: 5900  loss: 2.0146319457126083e-06  \u0007ccuracy: 99.59491525423729%\n",
            "epoch: 6  batch: 5950  loss: 0.0002294982987223193  \u0007ccuracy: 99.59663865546219%\n",
            "epoch: 6  batch: 6000  loss: 6.556497282872442e-07  \u0007ccuracy: 99.595%\n",
            "epoch: 7  batch: 50  loss: 0.0013013540301471949  \u0007ccuracy: 99.8%\n",
            "epoch: 7  batch: 100  loss: 1.1134006854263134e-05  \u0007ccuracy: 99.6%\n",
            "epoch: 7  batch: 150  loss: 0.000263627473032102  \u0007ccuracy: 99.6%\n",
            "epoch: 7  batch: 200  loss: 3.3378566399733245e-07  \u0007ccuracy: 99.55%\n",
            "epoch: 7  batch: 250  loss: 3.352983185322955e-05  \u0007ccuracy: 99.64%\n",
            "epoch: 7  batch: 300  loss: 7.808329974068329e-05  \u0007ccuracy: 99.63333333333334%\n",
            "epoch: 7  batch: 350  loss: 1.6569954368605977e-06  \u0007ccuracy: 99.68571428571428%\n",
            "epoch: 7  batch: 400  loss: 0.0009786880109459162  \u0007ccuracy: 99.725%\n",
            "epoch: 7  batch: 450  loss: 0.0023272475227713585  \u0007ccuracy: 99.73333333333333%\n",
            "epoch: 7  batch: 500  loss: 1.680841137385869e-06  \u0007ccuracy: 99.74%\n",
            "epoch: 7  batch: 550  loss: 1.955024345079437e-06  \u0007ccuracy: 99.76363636363637%\n",
            "epoch: 7  batch: 600  loss: 0.0008464744314551353  \u0007ccuracy: 99.75%\n",
            "epoch: 7  batch: 650  loss: 5.84124677516229e-07  \u0007ccuracy: 99.70769230769231%\n",
            "epoch: 7  batch: 700  loss: 2.384185648907078e-08  \u0007ccuracy: 99.71428571428571%\n",
            "epoch: 7  batch: 750  loss: 3.2901486974878935e-06  \u0007ccuracy: 99.69333333333333%\n",
            "epoch: 7  batch: 800  loss: 2.8252222818991868e-06  \u0007ccuracy: 99.7125%\n",
            "epoch: 7  batch: 850  loss: 0.0002769962593447417  \u0007ccuracy: 99.70588235294117%\n",
            "epoch: 7  batch: 900  loss: 1.0060764907393605e-05  \u0007ccuracy: 99.7%\n",
            "epoch: 7  batch: 950  loss: 0.0018400924745947123  \u0007ccuracy: 99.69473684210526%\n",
            "epoch: 7  batch: 1000  loss: 0.007748695556074381  \u0007ccuracy: 99.69%\n",
            "epoch: 7  batch: 1050  loss: 0.008185432292521  \u0007ccuracy: 99.6952380952381%\n",
            "epoch: 7  batch: 1100  loss: 0.0006608982803300023  \u0007ccuracy: 99.7%\n",
            "epoch: 7  batch: 1150  loss: 1.0728830091011332e-07  \u0007ccuracy: 99.71304347826087%\n",
            "epoch: 7  batch: 1200  loss: 0.00035924167605116963  \u0007ccuracy: 99.70833333333333%\n",
            "epoch: 7  batch: 1250  loss: 3.0060295102884993e-05  \u0007ccuracy: 99.704%\n",
            "epoch: 7  batch: 1300  loss: 1.5497201388825488e-07  \u0007ccuracy: 99.70769230769231%\n",
            "epoch: 7  batch: 1350  loss: 0.0023968685418367386  \u0007ccuracy: 99.71851851851852%\n",
            "epoch: 7  batch: 1400  loss: 1.5460253052879125e-05  \u0007ccuracy: 99.72142857142858%\n",
            "epoch: 7  batch: 1450  loss: 3.0993990094430046e-06  \u0007ccuracy: 99.71724137931035%\n",
            "epoch: 7  batch: 1500  loss: 1.580591379024554e-05  \u0007ccuracy: 99.72666666666667%\n",
            "epoch: 7  batch: 1550  loss: 6.818538622610504e-06  \u0007ccuracy: 99.73548387096774%\n",
            "epoch: 7  batch: 1600  loss: 1.764201806508936e-05  \u0007ccuracy: 99.7375%\n",
            "epoch: 7  batch: 1650  loss: 3.5285593185108155e-06  \u0007ccuracy: 99.72121212121212%\n",
            "epoch: 7  batch: 1700  loss: 1.7891765310196206e-05  \u0007ccuracy: 99.7235294117647%\n",
            "epoch: 7  batch: 1750  loss: 2.7676578611135483e-05  \u0007ccuracy: 99.72%\n",
            "epoch: 7  batch: 1800  loss: 5.805185719509609e-05  \u0007ccuracy: 99.72222222222223%\n",
            "epoch: 7  batch: 1850  loss: 0.00013037766620982438  \u0007ccuracy: 99.71891891891892%\n",
            "epoch: 7  batch: 1900  loss: 9.536697689327411e-07  \u0007ccuracy: 99.72631578947369%\n",
            "epoch: 7  batch: 1950  loss: 0.01276188064366579  \u0007ccuracy: 99.73333333333333%\n",
            "epoch: 7  batch: 2000  loss: 4.291462573746685e-06  \u0007ccuracy: 99.72%\n",
            "epoch: 7  batch: 2050  loss: 8.225412102547125e-07  \u0007ccuracy: 99.71219512195123%\n",
            "epoch: 7  batch: 2100  loss: 6.45918189547956e-05  \u0007ccuracy: 99.70952380952382%\n",
            "epoch: 7  batch: 2150  loss: 0.000659800018183887  \u0007ccuracy: 99.70697674418605%\n",
            "epoch: 7  batch: 2200  loss: 0.00013008170935790986  \u0007ccuracy: 99.70454545454545%\n",
            "epoch: 7  batch: 2250  loss: 1.9644812709884718e-05  \u0007ccuracy: 99.69333333333333%\n",
            "epoch: 7  batch: 2300  loss: 0.1558798998594284  \u0007ccuracy: 99.69130434782609%\n",
            "epoch: 7  batch: 2350  loss: 2.169593244616408e-06  \u0007ccuracy: 99.68510638297872%\n",
            "epoch: 7  batch: 2400  loss: 1.3947455954621546e-06  \u0007ccuracy: 99.68333333333334%\n",
            "epoch: 7  batch: 2450  loss: 0.002558463253080845  \u0007ccuracy: 99.68979591836735%\n",
            "epoch: 7  batch: 2500  loss: 1.192092824453539e-08  \u0007ccuracy: 99.692%\n",
            "epoch: 7  batch: 2550  loss: 0.5792883634567261  \u0007ccuracy: 99.69411764705882%\n",
            "epoch: 7  batch: 2600  loss: 0.0025098170153796673  \u0007ccuracy: 99.6923076923077%\n",
            "epoch: 7  batch: 2650  loss: 0.0007869000546634197  \u0007ccuracy: 99.69811320754717%\n",
            "epoch: 7  batch: 2700  loss: 0.34636086225509644  \u0007ccuracy: 99.7%\n",
            "epoch: 7  batch: 2750  loss: 0.0020677060820162296  \u0007ccuracy: 99.70181818181818%\n",
            "epoch: 7  batch: 2800  loss: 0.0004992409376427531  \u0007ccuracy: 99.69285714285714%\n",
            "epoch: 7  batch: 2850  loss: 0.39293530583381653  \u0007ccuracy: 99.6842105263158%\n",
            "epoch: 7  batch: 2900  loss: 6.830603524576873e-05  \u0007ccuracy: 99.67241379310344%\n",
            "epoch: 7  batch: 2950  loss: 2.145766586636455e-07  \u0007ccuracy: 99.66440677966102%\n",
            "epoch: 7  batch: 3000  loss: 0.0021598064340651035  \u0007ccuracy: 99.66333333333333%\n",
            "epoch: 7  batch: 3050  loss: 0.00026893947506323457  \u0007ccuracy: 99.65901639344263%\n",
            "epoch: 7  batch: 3100  loss: 0.00016050002886913717  \u0007ccuracy: 99.65161290322581%\n",
            "epoch: 7  batch: 3150  loss: 1.72842283063801e-05  \u0007ccuracy: 99.65714285714286%\n",
            "epoch: 7  batch: 3200  loss: 0.00012620676716323942  \u0007ccuracy: 99.653125%\n",
            "epoch: 7  batch: 3250  loss: 0.0002127668121829629  \u0007ccuracy: 99.65846153846154%\n",
            "epoch: 7  batch: 3300  loss: 0.012864110060036182  \u0007ccuracy: 99.66060606060606%\n",
            "epoch: 7  batch: 3350  loss: 0.00026903097750619054  \u0007ccuracy: 99.65970149253731%\n",
            "epoch: 7  batch: 3400  loss: 0.0045558372512459755  \u0007ccuracy: 99.65588235294118%\n",
            "epoch: 7  batch: 3450  loss: 0.00010203061538049951  \u0007ccuracy: 99.65797101449276%\n",
            "epoch: 7  batch: 3500  loss: 5.24509323440725e-06  \u0007ccuracy: 99.66%\n",
            "epoch: 7  batch: 3550  loss: 3.242469119868474e-06  \u0007ccuracy: 99.65633802816902%\n",
            "epoch: 7  batch: 3600  loss: 0.008852129802107811  \u0007ccuracy: 99.65833333333333%\n",
            "epoch: 7  batch: 3650  loss: 0.00015093479305505753  \u0007ccuracy: 99.66027397260274%\n",
            "epoch: 7  batch: 3700  loss: 2.9205871214799117e-06  \u0007ccuracy: 99.65405405405406%\n",
            "epoch: 7  batch: 3750  loss: 3.927490615751594e-05  \u0007ccuracy: 99.65333333333334%\n",
            "epoch: 7  batch: 3800  loss: 3.2016512705013156e-05  \u0007ccuracy: 99.65526315789474%\n",
            "epoch: 7  batch: 3850  loss: 3.124149588984437e-05  \u0007ccuracy: 99.65454545454546%\n",
            "epoch: 7  batch: 3900  loss: 0.00011192481179023162  \u0007ccuracy: 99.65384615384616%\n",
            "epoch: 7  batch: 3950  loss: 6.78551004966721e-05  \u0007ccuracy: 99.65569620253164%\n",
            "epoch: 7  batch: 4000  loss: 0.00023155838425736874  \u0007ccuracy: 99.655%\n",
            "epoch: 7  batch: 4050  loss: 0.00036268954863771796  \u0007ccuracy: 99.65925925925926%\n",
            "epoch: 7  batch: 4100  loss: 1.4662637113360688e-06  \u0007ccuracy: 99.66341463414633%\n",
            "epoch: 7  batch: 4150  loss: 0.0007479157065972686  \u0007ccuracy: 99.66265060240964%\n",
            "epoch: 7  batch: 4200  loss: 2.9680935767828487e-05  \u0007ccuracy: 99.66428571428571%\n",
            "epoch: 7  batch: 4250  loss: 1.1920921849650767e-07  \u0007ccuracy: 99.66823529411765%\n",
            "epoch: 7  batch: 4300  loss: 2.2718846594216302e-05  \u0007ccuracy: 99.66976744186047%\n",
            "epoch: 7  batch: 4350  loss: 0.000157900620251894  \u0007ccuracy: 99.67356321839081%\n",
            "epoch: 7  batch: 4400  loss: 0.004601077176630497  \u0007ccuracy: 99.67272727272727%\n",
            "epoch: 7  batch: 4450  loss: 2.5033932615770027e-07  \u0007ccuracy: 99.67415730337079%\n",
            "epoch: 7  batch: 4500  loss: 1.1086401627835585e-06  \u0007ccuracy: 99.67555555555556%\n",
            "epoch: 7  batch: 4550  loss: 5.6623339332873e-06  \u0007ccuracy: 99.67252747252748%\n",
            "epoch: 7  batch: 4600  loss: 0.0003364282310940325  \u0007ccuracy: 99.67608695652174%\n",
            "epoch: 7  batch: 4650  loss: 0.0017586376052349806  \u0007ccuracy: 99.67956989247311%\n",
            "epoch: 7  batch: 4700  loss: 1.4959672625991516e-05  \u0007ccuracy: 99.67659574468085%\n",
            "epoch: 7  batch: 4750  loss: 4.1960815906350035e-06  \u0007ccuracy: 99.6757894736842%\n",
            "epoch: 7  batch: 4800  loss: 5.297898314893246e-05  \u0007ccuracy: 99.67708333333333%\n",
            "epoch: 7  batch: 4850  loss: 0.5174127221107483  \u0007ccuracy: 99.67216494845361%\n",
            "epoch: 7  batch: 4900  loss: 0.001106287119910121  \u0007ccuracy: 99.66938775510204%\n",
            "epoch: 7  batch: 4950  loss: 1.978865157070686e-06  \u0007ccuracy: 99.66464646464647%\n",
            "epoch: 7  batch: 5000  loss: 5.054347184341168e-06  \u0007ccuracy: 99.656%\n",
            "epoch: 7  batch: 5050  loss: 0.06293033808469772  \u0007ccuracy: 99.65346534653466%\n",
            "epoch: 7  batch: 5100  loss: 0.000947363383602351  \u0007ccuracy: 99.65294117647059%\n",
            "epoch: 7  batch: 5150  loss: 3.0192240956239402e-05  \u0007ccuracy: 99.6504854368932%\n",
            "epoch: 7  batch: 5200  loss: 3.5762758443524945e-07  \u0007ccuracy: 99.64615384615385%\n",
            "epoch: 7  batch: 5250  loss: 4.73281615995802e-05  \u0007ccuracy: 99.64761904761905%\n",
            "epoch: 7  batch: 5300  loss: 1.192092824453539e-08  \u0007ccuracy: 99.65094339622641%\n",
            "epoch: 7  batch: 5350  loss: 5.364334356272593e-06  \u0007ccuracy: 99.64859813084112%\n",
            "epoch: 7  batch: 5400  loss: 0.3039200007915497  \u0007ccuracy: 99.64444444444445%\n",
            "epoch: 7  batch: 5450  loss: 1.7678064978099428e-05  \u0007ccuracy: 99.64036697247707%\n",
            "epoch: 7  batch: 5500  loss: 0.005369904451072216  \u0007ccuracy: 99.63636363636364%\n",
            "epoch: 7  batch: 5550  loss: 1.8596550717120408e-06  \u0007ccuracy: 99.63423423423423%\n",
            "epoch: 7  batch: 5600  loss: 5.483619247570459e-07  \u0007ccuracy: 99.63392857142857%\n",
            "epoch: 7  batch: 5650  loss: 0.06365930289030075  \u0007ccuracy: 99.6353982300885%\n",
            "epoch: 7  batch: 5700  loss: 0.00011574752716114745  \u0007ccuracy: 99.63508771929824%\n",
            "epoch: 7  batch: 5750  loss: 0.0014244616031646729  \u0007ccuracy: 99.62782608695652%\n",
            "epoch: 7  batch: 5800  loss: 3.588174195101601e-06  \u0007ccuracy: 99.62413793103448%\n",
            "epoch: 7  batch: 5850  loss: 5.9905734815401956e-05  \u0007ccuracy: 99.62222222222222%\n",
            "epoch: 7  batch: 5900  loss: 2.384185471271394e-08  \u0007ccuracy: 99.62372881355932%\n",
            "epoch: 7  batch: 5950  loss: 1.836911542341113e-05  \u0007ccuracy: 99.62521008403361%\n",
            "epoch: 7  batch: 6000  loss: 2.9047121643088758e-05  \u0007ccuracy: 99.625%\n",
            "epoch: 8  batch: 50  loss: 0.02621837891638279  \u0007ccuracy: 99.6%\n",
            "epoch: 8  batch: 100  loss: 5.170300210011192e-05  \u0007ccuracy: 99.8%\n",
            "epoch: 8  batch: 150  loss: 0.00039583485340699553  \u0007ccuracy: 99.8%\n",
            "epoch: 8  batch: 200  loss: 0.00013450512778945267  \u0007ccuracy: 99.6%\n",
            "epoch: 8  batch: 250  loss: 3.0994374355941545e-07  \u0007ccuracy: 99.68%\n",
            "epoch: 8  batch: 300  loss: 0.002573347184807062  \u0007ccuracy: 99.73333333333333%\n",
            "epoch: 8  batch: 350  loss: 0.013830127194523811  \u0007ccuracy: 99.74285714285715%\n",
            "epoch: 8  batch: 400  loss: 0.0007601656834594905  \u0007ccuracy: 99.775%\n",
            "epoch: 8  batch: 450  loss: 4.041143256472424e-06  \u0007ccuracy: 99.75555555555556%\n",
            "epoch: 8  batch: 500  loss: 7.939181159599684e-06  \u0007ccuracy: 99.76%\n",
            "epoch: 8  batch: 550  loss: 0.744609534740448  \u0007ccuracy: 99.72727272727273%\n",
            "epoch: 8  batch: 600  loss: 3.933899392905005e-07  \u0007ccuracy: 99.75%\n",
            "epoch: 8  batch: 650  loss: 3.075586164413835e-06  \u0007ccuracy: 99.76923076923077%\n",
            "epoch: 8  batch: 700  loss: 1.0728832933182275e-07  \u0007ccuracy: 99.78571428571429%\n",
            "epoch: 8  batch: 750  loss: 4.76837058727142e-08  \u0007ccuracy: 99.8%\n",
            "epoch: 8  batch: 800  loss: 6.437292654482007e-07  \u0007ccuracy: 99.8%\n",
            "epoch: 8  batch: 850  loss: 4.9232553465117235e-06  \u0007ccuracy: 99.81176470588235%\n",
            "epoch: 8  batch: 900  loss: 0.0001656827807892114  \u0007ccuracy: 99.81111111111112%\n",
            "epoch: 8  batch: 950  loss: 0.00037531854468397796  \u0007ccuracy: 99.81052631578947%\n",
            "epoch: 8  batch: 1000  loss: 1.192092824453539e-08  \u0007ccuracy: 99.81%\n",
            "epoch: 8  batch: 1050  loss: 0.00010508100967854261  \u0007ccuracy: 99.81904761904762%\n",
            "epoch: 8  batch: 1100  loss: 0.13289809226989746  \u0007ccuracy: 99.7909090909091%\n",
            "epoch: 8  batch: 1150  loss: 4.112685019208584e-06  \u0007ccuracy: 99.79130434782608%\n",
            "epoch: 8  batch: 1200  loss: 0.020243529230356216  \u0007ccuracy: 99.79166666666667%\n",
            "epoch: 8  batch: 1250  loss: 2.3841832330617763e-07  \u0007ccuracy: 99.792%\n",
            "epoch: 8  batch: 1300  loss: 6.556495577569876e-07  \u0007ccuracy: 99.8%\n",
            "epoch: 8  batch: 1350  loss: 1.5497153071919456e-06  \u0007ccuracy: 99.80740740740741%\n",
            "epoch: 8  batch: 1400  loss: 0.0007694175583310425  \u0007ccuracy: 99.80714285714286%\n",
            "epoch: 8  batch: 1450  loss: 0.008522238582372665  \u0007ccuracy: 99.80689655172414%\n",
            "epoch: 8  batch: 1500  loss: 1.3113016450461146e-07  \u0007ccuracy: 99.8%\n",
            "epoch: 8  batch: 1550  loss: 5.960463766996327e-08  \u0007ccuracy: 99.8%\n",
            "epoch: 8  batch: 1600  loss: 4.4926811824552715e-05  \u0007ccuracy: 99.78125%\n",
            "epoch: 8  batch: 1650  loss: 3.3139774586743442e-06  \u0007ccuracy: 99.78181818181818%\n",
            "epoch: 8  batch: 1700  loss: 0.00012870150385424495  \u0007ccuracy: 99.78235294117647%\n",
            "epoch: 8  batch: 1750  loss: 1.1193440514034592e-05  \u0007ccuracy: 99.78285714285714%\n",
            "epoch: 8  batch: 1800  loss: 7.855712283344474e-06  \u0007ccuracy: 99.78333333333333%\n",
            "epoch: 8  batch: 1850  loss: 0.00037706454168073833  \u0007ccuracy: 99.77837837837838%\n",
            "epoch: 8  batch: 1900  loss: 2.354117350478191e-05  \u0007ccuracy: 99.77894736842106%\n",
            "epoch: 8  batch: 1950  loss: 7.974963409651536e-06  \u0007ccuracy: 99.77948717948718%\n",
            "epoch: 8  batch: 2000  loss: 1.4542541066475678e-05  \u0007ccuracy: 99.785%\n",
            "epoch: 8  batch: 2050  loss: 3.838508746412117e-06  \u0007ccuracy: 99.79024390243903%\n",
            "epoch: 8  batch: 2100  loss: 1.955021843969007e-06  \u0007ccuracy: 99.79047619047618%\n",
            "epoch: 8  batch: 2150  loss: 2.503392693142814e-07  \u0007ccuracy: 99.78139534883721%\n",
            "epoch: 8  batch: 2200  loss: 0.009581620804965496  \u0007ccuracy: 99.77272727272727%\n",
            "epoch: 8  batch: 2250  loss: 0.0006101016188040376  \u0007ccuracy: 99.77333333333333%\n",
            "epoch: 8  batch: 2300  loss: 0.0023378196638077497  \u0007ccuracy: 99.7695652173913%\n",
            "epoch: 8  batch: 2350  loss: 8.583043609178276e-07  \u0007ccuracy: 99.76170212765958%\n",
            "epoch: 8  batch: 2400  loss: 0.001224455889314413  \u0007ccuracy: 99.76666666666667%\n",
            "epoch: 8  batch: 2450  loss: 3.70734119314875e-06  \u0007ccuracy: 99.76326530612245%\n",
            "epoch: 8  batch: 2500  loss: 5.367002449929714e-05  \u0007ccuracy: 99.764%\n",
            "epoch: 8  batch: 2550  loss: 6.556501830345951e-07  \u0007ccuracy: 99.7607843137255%\n",
            "epoch: 8  batch: 2600  loss: 1.1920921849650767e-07  \u0007ccuracy: 99.75384615384615%\n",
            "epoch: 8  batch: 2650  loss: 1.1109772458439693e-05  \u0007ccuracy: 99.75094339622642%\n",
            "epoch: 8  batch: 2700  loss: 3.611979991546832e-06  \u0007ccuracy: 99.75555555555556%\n",
            "epoch: 8  batch: 2750  loss: 1.156327016360592e-06  \u0007ccuracy: 99.74545454545455%\n",
            "epoch: 8  batch: 2800  loss: 4.88756995764561e-07  \u0007ccuracy: 99.74642857142857%\n",
            "epoch: 8  batch: 2850  loss: 0.001610076054930687  \u0007ccuracy: 99.73333333333333%\n",
            "epoch: 8  batch: 2900  loss: 1.711776712909341e-05  \u0007ccuracy: 99.73103448275862%\n",
            "epoch: 8  batch: 2950  loss: 0.00012058203719789162  \u0007ccuracy: 99.72542372881355%\n",
            "epoch: 8  batch: 3000  loss: 0.0002164568577427417  \u0007ccuracy: 99.72333333333333%\n",
            "epoch: 8  batch: 3050  loss: 0.07664033025503159  \u0007ccuracy: 99.72131147540983%\n",
            "epoch: 8  batch: 3100  loss: 0.00046706554712727666  \u0007ccuracy: 99.7258064516129%\n",
            "epoch: 8  batch: 3150  loss: 0.003047002013772726  \u0007ccuracy: 99.72380952380952%\n",
            "epoch: 8  batch: 3200  loss: 0.0027961679734289646  \u0007ccuracy: 99.725%\n",
            "epoch: 8  batch: 3250  loss: 0.0003584060468710959  \u0007ccuracy: 99.72923076923077%\n",
            "epoch: 8  batch: 3300  loss: 1.5497201388825488e-07  \u0007ccuracy: 99.72424242424242%\n",
            "epoch: 8  batch: 3350  loss: 1.1193162208655849e-05  \u0007ccuracy: 99.72835820895523%\n",
            "epoch: 8  batch: 3400  loss: 0.009756531566381454  \u0007ccuracy: 99.73235294117647%\n",
            "epoch: 8  batch: 3450  loss: 0.0002832781174220145  \u0007ccuracy: 99.72173913043478%\n",
            "epoch: 8  batch: 3500  loss: 1.6259182302746922e-05  \u0007ccuracy: 99.72285714285714%\n",
            "epoch: 8  batch: 3550  loss: 1.287456711906998e-06  \u0007ccuracy: 99.72112676056338%\n",
            "epoch: 8  batch: 3600  loss: 1.6212410400839872e-06  \u0007ccuracy: 99.725%\n",
            "epoch: 8  batch: 3650  loss: 3.8146924907778157e-07  \u0007ccuracy: 99.72876712328767%\n",
            "epoch: 8  batch: 3700  loss: 6.556312200700631e-06  \u0007ccuracy: 99.72972972972973%\n",
            "epoch: 8  batch: 3750  loss: 1.4424228993448196e-06  \u0007ccuracy: 99.71466666666667%\n",
            "epoch: 8  batch: 3800  loss: 0.011954803951084614  \u0007ccuracy: 99.7078947368421%\n",
            "epoch: 8  batch: 3850  loss: 4.649154448088666e-07  \u0007ccuracy: 99.7038961038961%\n",
            "epoch: 8  batch: 3900  loss: 0.021271301433444023  \u0007ccuracy: 99.6974358974359%\n",
            "epoch: 8  batch: 3950  loss: 8.105938832159154e-06  \u0007ccuracy: 99.69620253164557%\n",
            "epoch: 8  batch: 4000  loss: 3.070637467317283e-05  \u0007ccuracy: 99.7%\n",
            "epoch: 8  batch: 4050  loss: 4.76837058727142e-08  \u0007ccuracy: 99.70370370370371%\n",
            "epoch: 8  batch: 4100  loss: 0.0004882227221969515  \u0007ccuracy: 99.70487804878049%\n",
            "epoch: 8  batch: 4150  loss: 1.7009735529427417e-05  \u0007ccuracy: 99.70602409638555%\n",
            "epoch: 8  batch: 4200  loss: 1.36966318677878e-05  \u0007ccuracy: 99.70952380952382%\n",
            "epoch: 8  batch: 4250  loss: 4.029213869216619e-06  \u0007ccuracy: 99.7129411764706%\n",
            "epoch: 8  batch: 4300  loss: 7.152556236178498e-08  \u0007ccuracy: 99.71627906976744%\n",
            "epoch: 8  batch: 4350  loss: 8.904681635613088e-06  \u0007ccuracy: 99.71724137931035%\n",
            "epoch: 8  batch: 4400  loss: 0.001035710098221898  \u0007ccuracy: 99.7159090909091%\n",
            "epoch: 8  batch: 4450  loss: 0.00024545026826672256  \u0007ccuracy: 99.71460674157304%\n",
            "epoch: 8  batch: 4500  loss: 7.271531103469897e-06  \u0007ccuracy: 99.71555555555555%\n",
            "epoch: 8  batch: 4550  loss: 1.585477548360359e-06  \u0007ccuracy: 99.71648351648352%\n",
            "epoch: 8  batch: 4600  loss: 2.7060191314376425e-06  \u0007ccuracy: 99.71739130434783%\n",
            "epoch: 8  batch: 4650  loss: 1.7224261682713404e-05  \u0007ccuracy: 99.72043010752688%\n",
            "epoch: 8  batch: 4700  loss: 2.861018799649173e-07  \u0007ccuracy: 99.72340425531915%\n",
            "epoch: 8  batch: 4750  loss: 0.004661048296838999  \u0007ccuracy: 99.72421052631579%\n",
            "epoch: 8  batch: 4800  loss: 0.00011504261055961251  \u0007ccuracy: 99.725%\n",
            "epoch: 8  batch: 4850  loss: 0.00032054827897809446  \u0007ccuracy: 99.72371134020618%\n",
            "epoch: 8  batch: 4900  loss: 0.004171567969024181  \u0007ccuracy: 99.72448979591837%\n",
            "epoch: 8  batch: 4950  loss: 0.00039345360710285604  \u0007ccuracy: 99.72121212121212%\n",
            "epoch: 8  batch: 5000  loss: 4.875763988820836e-05  \u0007ccuracy: 99.72%\n",
            "epoch: 8  batch: 5050  loss: 9.536739753457368e-08  \u0007ccuracy: 99.71683168316832%\n",
            "epoch: 8  batch: 5100  loss: 9.89434624898422e-07  \u0007ccuracy: 99.71176470588236%\n",
            "epoch: 8  batch: 5150  loss: 0.0007309571374207735  \u0007ccuracy: 99.70873786407768%\n",
            "epoch: 8  batch: 5200  loss: 5.125986035636743e-07  \u0007ccuracy: 99.70769230769231%\n",
            "epoch: 8  batch: 5250  loss: 1.0132739589607809e-06  \u0007ccuracy: 99.70666666666666%\n",
            "epoch: 8  batch: 5300  loss: 0.0001889498671516776  \u0007ccuracy: 99.7%\n",
            "epoch: 8  batch: 5350  loss: 7.879478289396502e-06  \u0007ccuracy: 99.70093457943925%\n",
            "epoch: 8  batch: 5400  loss: 7.164241196733201e-06  \u0007ccuracy: 99.69814814814815%\n",
            "epoch: 8  batch: 5450  loss: 2.384185471271394e-08  \u0007ccuracy: 99.70091743119266%\n",
            "epoch: 8  batch: 5500  loss: 5.001419776817784e-05  \u0007ccuracy: 99.70181818181818%\n",
            "epoch: 8  batch: 5550  loss: 6.417482654796913e-05  \u0007ccuracy: 99.70270270270271%\n",
            "epoch: 8  batch: 5600  loss: 3.7669426546926843e-06  \u0007ccuracy: 99.7%\n",
            "epoch: 8  batch: 5650  loss: 0.00011258969607297331  \u0007ccuracy: 99.70265486725664%\n",
            "epoch: 8  batch: 5700  loss: 0.0002989186905324459  \u0007ccuracy: 99.69473684210526%\n",
            "epoch: 8  batch: 5750  loss: 1.661640635575168e-05  \u0007ccuracy: 99.69217391304348%\n",
            "epoch: 8  batch: 5800  loss: 0.0008384178509004414  \u0007ccuracy: 99.6896551724138%\n",
            "epoch: 8  batch: 5850  loss: 0.0003572088317014277  \u0007ccuracy: 99.68717948717949%\n",
            "epoch: 8  batch: 5900  loss: 0.009410923346877098  \u0007ccuracy: 99.68813559322034%\n",
            "epoch: 8  batch: 5950  loss: 2.9801958589814603e-06  \u0007ccuracy: 99.68739495798319%\n",
            "epoch: 8  batch: 6000  loss: 1.0490385875527863e-06  \u0007ccuracy: 99.68333333333334%\n",
            "epoch: 9  batch: 50  loss: 0.0011907662265002728  \u0007ccuracy: 99.6%\n",
            "epoch: 9  batch: 100  loss: 0.00011329477274557576  \u0007ccuracy: 99.3%\n",
            "epoch: 9  batch: 150  loss: 1.2755112038576044e-05  \u0007ccuracy: 99.4%\n",
            "epoch: 9  batch: 200  loss: 1.2874527328676777e-06  \u0007ccuracy: 99.45%\n",
            "epoch: 9  batch: 250  loss: 0.00017737339658197016  \u0007ccuracy: 99.4%\n",
            "epoch: 9  batch: 300  loss: 8.964298103819601e-06  \u0007ccuracy: 99.5%\n",
            "epoch: 9  batch: 350  loss: 1.001356508822937e-06  \u0007ccuracy: 99.57142857142857%\n",
            "epoch: 9  batch: 400  loss: 1.0728831512096804e-07  \u0007ccuracy: 99.625%\n",
            "epoch: 9  batch: 450  loss: 6.936789577594027e-05  \u0007ccuracy: 99.66666666666667%\n",
            "epoch: 9  batch: 500  loss: 0.0  \u0007ccuracy: 99.7%\n",
            "epoch: 9  batch: 550  loss: 4.6397410187637433e-05  \u0007ccuracy: 99.72727272727273%\n",
            "epoch: 9  batch: 600  loss: 1.712971970846411e-05  \u0007ccuracy: 99.68333333333334%\n",
            "epoch: 9  batch: 650  loss: 1.1920921849650767e-07  \u0007ccuracy: 99.67692307692307%\n",
            "epoch: 9  batch: 700  loss: 4.0769155020825565e-06  \u0007ccuracy: 99.68571428571428%\n",
            "epoch: 9  batch: 750  loss: 1.5174303371168207e-05  \u0007ccuracy: 99.68%\n",
            "epoch: 9  batch: 800  loss: 8.135188545566052e-05  \u0007ccuracy: 99.6875%\n",
            "epoch: 9  batch: 850  loss: 3.004029622388771e-06  \u0007ccuracy: 99.69411764705882%\n",
            "epoch: 9  batch: 900  loss: 2.9802305334669654e-07  \u0007ccuracy: 99.71111111111111%\n",
            "epoch: 9  batch: 950  loss: 1.907347240148738e-07  \u0007ccuracy: 99.70526315789473%\n",
            "epoch: 9  batch: 1000  loss: 1.0728830091011332e-07  \u0007ccuracy: 99.7%\n",
            "epoch: 9  batch: 1050  loss: 3.714169724844396e-05  \u0007ccuracy: 99.70476190476191%\n",
            "epoch: 9  batch: 1100  loss: 0.00025322005967609584  \u0007ccuracy: 99.7%\n",
            "epoch: 9  batch: 1150  loss: 0.0015413594665005803  \u0007ccuracy: 99.68695652173913%\n",
            "epoch: 9  batch: 1200  loss: 0.001401575980708003  \u0007ccuracy: 99.69166666666666%\n",
            "epoch: 9  batch: 1250  loss: 3.379115150892176e-05  \u0007ccuracy: 99.688%\n",
            "epoch: 9  batch: 1300  loss: 0.014498206786811352  \u0007ccuracy: 99.6923076923077%\n",
            "epoch: 9  batch: 1350  loss: 0.07615984976291656  \u0007ccuracy: 99.6962962962963%\n",
            "epoch: 9  batch: 1400  loss: 0.00028141209622845054  \u0007ccuracy: 99.70714285714286%\n",
            "epoch: 9  batch: 1450  loss: 5.94563789491076e-05  \u0007ccuracy: 99.71034482758621%\n",
            "epoch: 9  batch: 1500  loss: 7.66496032156283e-06  \u0007ccuracy: 99.71333333333334%\n",
            "epoch: 9  batch: 1550  loss: 1.4305105366929638e-07  \u0007ccuracy: 99.71612903225807%\n",
            "epoch: 9  batch: 1600  loss: 3.298196679679677e-05  \u0007ccuracy: 99.71875%\n",
            "epoch: 9  batch: 1650  loss: 5.090154445497319e-06  \u0007ccuracy: 99.72727272727273%\n",
            "epoch: 9  batch: 1700  loss: 0.0009833230869844556  \u0007ccuracy: 99.73529411764706%\n",
            "epoch: 9  batch: 1750  loss: 4.291442564863246e-06  \u0007ccuracy: 99.73714285714286%\n",
            "epoch: 9  batch: 1800  loss: 0.0043878573924303055  \u0007ccuracy: 99.72777777777777%\n",
            "epoch: 9  batch: 1850  loss: 2.1815087620780105e-06  \u0007ccuracy: 99.72432432432433%\n",
            "epoch: 9  batch: 1900  loss: 7.510157047363464e-07  \u0007ccuracy: 99.73157894736842%\n",
            "epoch: 9  batch: 1950  loss: 2.3245556803885847e-06  \u0007ccuracy: 99.72820512820513%\n",
            "epoch: 9  batch: 2000  loss: 5.543147381104063e-06  \u0007ccuracy: 99.73%\n",
            "epoch: 9  batch: 2050  loss: 8.344647994817933e-08  \u0007ccuracy: 99.73170731707317%\n",
            "epoch: 9  batch: 2100  loss: 1.108644028136041e-06  \u0007ccuracy: 99.72857142857143%\n",
            "epoch: 9  batch: 2150  loss: 0.23540011048316956  \u0007ccuracy: 99.72558139534884%\n",
            "epoch: 9  batch: 2200  loss: 7.088058919180185e-05  \u0007ccuracy: 99.72727272727273%\n",
            "epoch: 9  batch: 2250  loss: 0.00010910040873568505  \u0007ccuracy: 99.72888888888889%\n",
            "epoch: 9  batch: 2300  loss: 0.0005715956795029342  \u0007ccuracy: 99.72173913043478%\n",
            "epoch: 9  batch: 2350  loss: 0.010016484186053276  \u0007ccuracy: 99.71914893617021%\n",
            "epoch: 9  batch: 2400  loss: 1.208716093969997e-05  \u0007ccuracy: 99.69583333333334%\n",
            "epoch: 9  batch: 2450  loss: 2.0265558475784928e-07  \u0007ccuracy: 99.70204081632653%\n",
            "epoch: 9  batch: 2500  loss: 3.8306530768750235e-05  \u0007ccuracy: 99.704%\n",
            "epoch: 9  batch: 2550  loss: 0.03032907471060753  \u0007ccuracy: 99.70196078431373%\n",
            "epoch: 9  batch: 2600  loss: 1.1527045899129007e-05  \u0007ccuracy: 99.70384615384616%\n",
            "epoch: 9  batch: 2650  loss: 7.665887096663937e-05  \u0007ccuracy: 99.70188679245283%\n",
            "epoch: 9  batch: 2700  loss: 8.106201789814804e-07  \u0007ccuracy: 99.69259259259259%\n",
            "epoch: 9  batch: 2750  loss: 0.0004405029467307031  \u0007ccuracy: 99.69454545454545%\n",
            "epoch: 9  batch: 2800  loss: 3.695482178045495e-07  \u0007ccuracy: 99.69285714285714%\n",
            "epoch: 9  batch: 2850  loss: 0.001193415024317801  \u0007ccuracy: 99.68771929824561%\n",
            "epoch: 9  batch: 2900  loss: 0.35800236463546753  \u0007ccuracy: 99.68275862068965%\n",
            "epoch: 9  batch: 2950  loss: 6.914127652635216e-07  \u0007ccuracy: 99.68474576271187%\n",
            "epoch: 9  batch: 3000  loss: 1.192092824453539e-08  \u0007ccuracy: 99.68666666666667%\n",
            "epoch: 9  batch: 3050  loss: 1.9073468138230965e-07  \u0007ccuracy: 99.69180327868852%\n",
            "epoch: 9  batch: 3100  loss: 0.03198695927858353  \u0007ccuracy: 99.69032258064516%\n",
            "epoch: 9  batch: 3150  loss: 3.0397914088098332e-06  \u0007ccuracy: 99.67936507936508%\n",
            "epoch: 9  batch: 3200  loss: 5.483616405399516e-07  \u0007ccuracy: 99.678125%\n",
            "epoch: 9  batch: 3250  loss: 7.03332830198633e-07  \u0007ccuracy: 99.67384615384616%\n",
            "epoch: 9  batch: 3300  loss: 0.001836186507716775  \u0007ccuracy: 99.67575757575757%\n",
            "epoch: 9  batch: 3350  loss: 8.940667726164975e-07  \u0007ccuracy: 99.67462686567164%\n",
            "epoch: 9  batch: 3400  loss: 0.001427148119546473  \u0007ccuracy: 99.6735294117647%\n",
            "epoch: 9  batch: 3450  loss: 2.181507397835958e-06  \u0007ccuracy: 99.67826086956522%\n",
            "epoch: 9  batch: 3500  loss: 1.0180134268011898e-05  \u0007ccuracy: 99.68285714285715%\n",
            "epoch: 9  batch: 3550  loss: 0.0006003209273330867  \u0007ccuracy: 99.68169014084508%\n",
            "epoch: 9  batch: 3600  loss: 2.647291694302112e-05  \u0007ccuracy: 99.68333333333334%\n",
            "epoch: 9  batch: 3650  loss: 5.524226071429439e-05  \u0007ccuracy: 99.68493150684931%\n",
            "epoch: 9  batch: 3700  loss: 0.00035789862158708274  \u0007ccuracy: 99.68648648648649%\n",
            "epoch: 9  batch: 3750  loss: 2.9921091027063085e-06  \u0007ccuracy: 99.68%\n",
            "epoch: 9  batch: 3800  loss: 0.0010423781350255013  \u0007ccuracy: 99.68157894736842%\n",
            "epoch: 9  batch: 3850  loss: 2.6032057576230727e-05  \u0007ccuracy: 99.68571428571428%\n",
            "epoch: 9  batch: 3900  loss: 0.005031890701502562  \u0007ccuracy: 99.68717948717949%\n",
            "epoch: 9  batch: 3950  loss: 5.960463766996327e-08  \u0007ccuracy: 99.68101265822784%\n",
            "epoch: 9  batch: 4000  loss: 2.503392693142814e-07  \u0007ccuracy: 99.68%\n",
            "epoch: 9  batch: 4050  loss: 2.0265390503482195e-06  \u0007ccuracy: 99.68148148148148%\n",
            "epoch: 9  batch: 4100  loss: 0.03502976894378662  \u0007ccuracy: 99.67317073170732%\n",
            "epoch: 9  batch: 4150  loss: 7.745604671072215e-05  \u0007ccuracy: 99.67469879518072%\n",
            "epoch: 9  batch: 4200  loss: 6.675702479697065e-07  \u0007ccuracy: 99.67142857142858%\n",
            "epoch: 9  batch: 4250  loss: 1.1920925402364446e-07  \u0007ccuracy: 99.67058823529412%\n",
            "epoch: 9  batch: 4300  loss: 0.0  \u0007ccuracy: 99.67441860465117%\n",
            "epoch: 9  batch: 4350  loss: 6.198876008056686e-07  \u0007ccuracy: 99.67356321839081%\n",
            "epoch: 9  batch: 4400  loss: 2.384185471271394e-08  \u0007ccuracy: 99.66818181818182%\n",
            "epoch: 9  batch: 4450  loss: 2.5749020551302237e-06  \u0007ccuracy: 99.67191011235956%\n",
            "epoch: 9  batch: 4500  loss: 2.8967504022148205e-06  \u0007ccuracy: 99.66666666666667%\n",
            "epoch: 9  batch: 4550  loss: 0.10689399391412735  \u0007ccuracy: 99.66373626373627%\n",
            "epoch: 9  batch: 4600  loss: 2.0263831174816005e-05  \u0007ccuracy: 99.6608695652174%\n",
            "epoch: 9  batch: 4650  loss: 1.809435707400553e-05  \u0007ccuracy: 99.66236559139784%\n",
            "epoch: 9  batch: 4700  loss: 6.034961552359164e-05  \u0007ccuracy: 99.66382978723404%\n",
            "epoch: 9  batch: 4750  loss: 0.005835408344864845  \u0007ccuracy: 99.66105263157895%\n",
            "epoch: 9  batch: 4800  loss: 6.437288107008499e-07  \u0007ccuracy: 99.66041666666666%\n",
            "epoch: 9  batch: 4850  loss: 4.865468144998886e-05  \u0007ccuracy: 99.65979381443299%\n",
            "epoch: 9  batch: 4900  loss: 0.00040391640504822135  \u0007ccuracy: 99.65714285714286%\n",
            "epoch: 9  batch: 4950  loss: 0.00047907335101626813  \u0007ccuracy: 99.65858585858585%\n",
            "epoch: 9  batch: 5000  loss: 0.00047810058458708227  \u0007ccuracy: 99.656%\n",
            "epoch: 9  batch: 5050  loss: 0.0027134933043271303  \u0007ccuracy: 99.65940594059406%\n",
            "epoch: 9  batch: 5100  loss: 2.88484375232656e-06  \u0007ccuracy: 99.66078431372549%\n",
            "epoch: 9  batch: 5150  loss: 0.00013866295921616256  \u0007ccuracy: 99.66019417475728%\n",
            "epoch: 9  batch: 5200  loss: 2.682193098735297e-06  \u0007ccuracy: 99.65384615384616%\n",
            "epoch: 9  batch: 5250  loss: 0.0005466758157126606  \u0007ccuracy: 99.65333333333334%\n",
            "epoch: 9  batch: 5300  loss: 0.15165916085243225  \u0007ccuracy: 99.64528301886793%\n",
            "epoch: 9  batch: 5350  loss: 0.0057179369032382965  \u0007ccuracy: 99.64485981308411%\n",
            "epoch: 9  batch: 5400  loss: 4.7086823542485945e-06  \u0007ccuracy: 99.6462962962963%\n",
            "epoch: 9  batch: 5450  loss: 1.656996573728975e-06  \u0007ccuracy: 99.64770642201835%\n",
            "epoch: 9  batch: 5500  loss: 0.0006527940277010202  \u0007ccuracy: 99.64909090909092%\n",
            "epoch: 9  batch: 5550  loss: 0.0009491476230323315  \u0007ccuracy: 99.64864864864865%\n",
            "epoch: 9  batch: 5600  loss: 9.536739753457368e-08  \u0007ccuracy: 99.65178571428571%\n",
            "epoch: 9  batch: 5650  loss: 0.0001827119995141402  \u0007ccuracy: 99.65309734513275%\n",
            "epoch: 9  batch: 5700  loss: 9.188098920276389e-05  \u0007ccuracy: 99.65438596491228%\n",
            "epoch: 9  batch: 5750  loss: 6.318074952105235e-07  \u0007ccuracy: 99.65565217391304%\n",
            "epoch: 9  batch: 5800  loss: 7.152556236178498e-08  \u0007ccuracy: 99.65172413793104%\n",
            "epoch: 9  batch: 5850  loss: 4.4107378016633447e-07  \u0007ccuracy: 99.65128205128205%\n",
            "epoch: 9  batch: 5900  loss: 5.84125075420161e-07  \u0007ccuracy: 99.65254237288136%\n",
            "epoch: 9  batch: 5950  loss: 3.576278118089249e-08  \u0007ccuracy: 99.65546218487395%\n",
            "epoch: 9  batch: 6000  loss: 0.00023164127196650952  \u0007ccuracy: 99.65666666666667%\n",
            "total time: 521.1817486286163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = [t.item() for t in train_losses]\n",
        "test_losses = [t.item() for t in test_losses]\n",
        "train_correct = [t/100 for t in train_correct]\n",
        "test_correct = [t/100 for t in test_correct]\n",
        "plt.plot(train_losses, label='training loss')\n",
        "plt.plot(test_losses, label='validation loss')\n",
        "plt.plot(train_correct, label='training accuracy')\n",
        "plt.plot(test_correct, label='validation accuracy')\n",
        "plt.title('Loss at the end of each epoch')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "PNPyun3Ivf7P",
        "outputId": "ae7a520d-6d7e-46cf-9ed3-f68fadbf4c10"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_losses' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1196408865.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_correct\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_correct\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lWDp_9wk1dzk"
      }
    }
  ]
}